{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Greenv2 Project documentation with Markdown. Project Context The customer needs to maintain multiple websites both from a content point of view as well as from the CMS software point of view. Spinning up VSI's for each website and updating manually all of these boxes would be very time consuming (and also expensive). By running the CMS software in containers and managing software updates out of github, updating all the websites can be highly automated through CI/CD. This will also involve using one or more of our Database as a Service offerings to manage to content and/or adding CIS on top for global load balancing. Client requires CMS-as-a-Service Drupal is the CMS technology of choice Many competitors in this space; mostly open source With CMS-aaS we must provide a DevOps solution Dependencies with Drupal: LAMP stack and Caching End goal: To provide the fastest solution to get new content into Production Functional requirements Separate environments for: Dev; Test; Production; Site must be hosted on public cloud; Site must be accessible globally; Code deployment can be done using FTP/SFTP; Content distribution using CDN; SMTP setup to facilitate email communication to support \u201cContact Us\u201d function in the website; Non-functional requirements Security: Enterprise grade firewalling; DDOS protection; Availability: High Availability of the infrastructure platform; Scalability: Scalable infrastructure with possible future expansion of the website. Infrastructure support for services around DNS mapping and Certificate installation. Logical architecture Landscape diagram of the services used When custom code is checked into this repository, it triggers a Docker image build which stores the images into a private container registry that analyzes the security of the images. These images are then rolled out across the Kubernetes cluster through staging and production gates. Data from production can be synchronized back to staging to ensure the environments are as close as possible. Setup the environment and deploy the cluster One time Container Service and Cloud data services setup See the Container Service Kubernetes and IBM Cloud services (MySQL, Redis, Memcached) configuration instructions . Building and deploying the first set of containers See the Docker container build and Kubernetes deployment instructions . Ongoing development and operations with GitHub commits See the ongoing development instructions . And the work in progress DevOps pipeline docs . This shows how container images are rebuilt and how to address security issues detected by the IBM Vulnerability Advisor. Synchronizing data from production back to staging There are two synchronization scripts that can be invoked to bring user generated changes to files or data from production back into the staging environment. You can also execute other scripts inside the containers as well. Security The web site uses TLS certificate to secure the data transfer. The domain is provided by IBM Cloud Domain name Service and it is managed by IBM Cloud Internet Service aka CIS . IBM Certificate Manager store the certificate and has the ability to keep track of the expiration date of the certificate. IBM Certificate Manager is able to renew automatically the certificate before its expiration date. IBM Certificate Manager uses a webhook to an IBM Function (serverless) with a smart small code to renew the certificate. License Apache 2.0","title":"Home"},{"location":"#greenv2","text":"Project documentation with Markdown.","title":"Greenv2"},{"location":"#project-context","text":"The customer needs to maintain multiple websites both from a content point of view as well as from the CMS software point of view. Spinning up VSI's for each website and updating manually all of these boxes would be very time consuming (and also expensive). By running the CMS software in containers and managing software updates out of github, updating all the websites can be highly automated through CI/CD. This will also involve using one or more of our Database as a Service offerings to manage to content and/or adding CIS on top for global load balancing. Client requires CMS-as-a-Service Drupal is the CMS technology of choice Many competitors in this space; mostly open source With CMS-aaS we must provide a DevOps solution Dependencies with Drupal: LAMP stack and Caching End goal: To provide the fastest solution to get new content into Production","title":"Project Context"},{"location":"#functional-requirements","text":"Separate environments for: Dev; Test; Production; Site must be hosted on public cloud; Site must be accessible globally; Code deployment can be done using FTP/SFTP; Content distribution using CDN; SMTP setup to facilitate email communication to support \u201cContact Us\u201d function in the website;","title":"Functional requirements"},{"location":"#non-functional-requirements","text":"Security: Enterprise grade firewalling; DDOS protection; Availability: High Availability of the infrastructure platform; Scalability: Scalable infrastructure with possible future expansion of the website. Infrastructure support for services around DNS mapping and Certificate installation.","title":"Non-functional requirements"},{"location":"#logical-architecture","text":"","title":"Logical architecture"},{"location":"#landscape-diagram-of-the-services-used","text":"When custom code is checked into this repository, it triggers a Docker image build which stores the images into a private container registry that analyzes the security of the images. These images are then rolled out across the Kubernetes cluster through staging and production gates. Data from production can be synchronized back to staging to ensure the environments are as close as possible.","title":"Landscape diagram of the services used"},{"location":"#setup-the-environment-and-deploy-the-cluster","text":"","title":"Setup the environment and deploy the cluster"},{"location":"#one-time-container-service-and-cloud-data-services-setup","text":"See the Container Service Kubernetes and IBM Cloud services (MySQL, Redis, Memcached) configuration instructions .","title":"One time Container Service and Cloud data services setup"},{"location":"#building-and-deploying-the-first-set-of-containers","text":"See the Docker container build and Kubernetes deployment instructions .","title":"Building and deploying the first set of containers"},{"location":"#ongoing-development-and-operations-with-github-commits","text":"See the ongoing development instructions . And the work in progress DevOps pipeline docs . This shows how container images are rebuilt and how to address security issues detected by the IBM Vulnerability Advisor.","title":"Ongoing development and operations with GitHub commits"},{"location":"#synchronizing-data-from-production-back-to-staging","text":"There are two synchronization scripts that can be invoked to bring user generated changes to files or data from production back into the staging environment. You can also execute other scripts inside the containers as well.","title":"Synchronizing data from production back to staging"},{"location":"#security","text":"The web site uses TLS certificate to secure the data transfer. The domain is provided by IBM Cloud Domain name Service and it is managed by IBM Cloud Internet Service aka CIS . IBM Certificate Manager store the certificate and has the ability to keep track of the expiration date of the certificate. IBM Certificate Manager is able to renew automatically the certificate before its expiration date. IBM Certificate Manager uses a webhook to an IBM Function (serverless) with a smart small code to renew the certificate.","title":"Security"},{"location":"#license","text":"Apache 2.0","title":"License"},{"location":"CERTIFICATE-SETUP/","text":"TLS-CERTIFICATE Setup Guide to all available configuration settings. Prerequesite : IBM Cloud Account IBM Cloud Components needed The project needs to have a secure website based on TLS encryption, hence https protocol is used, this latter needs a valid and up-to-date certificate. IBM Certificate Manager is used to store and to manage the certificate IBM Certificate Manager check expiration date and if needed call a webhook Function Service to renew the certificate A certificate is generated for a domain name, this one is handled by IBM Cloud Internet Service , the domain registrar is handle by IBM Cloud Domain Name Service . IBM Cloud Domain Name Service You may register a new domain here . Click on CREATE . Provide a domain name, the price may change depending on the extension (.com, .net, .org, ...) and the number of years chosen. You may click on Check Availability to check whether or not the domain name provided is available. You may proceed by clicking on Continue if your domain name is available Fill up the form and take care about the email address which will be used to validate your purchase. Click on Order Now to validate the process. After clicking on the link in the mail sent to your mailbox, you should have valid domain name such as follows after a few minutes : IBM Cloud Internet Service (CIS) You may create an IBM CIS instance here . Click on CREATE . Click on Let's get started . Provided the domain name you created on the previous stage and Click on Connect and continue . The system will automatically detect the NameServers attached by default (your registrar setup) to your domain, and proposed a list of CIS NameServers to replace, for instance : ns1.softlayer.com - ns015.name.cloud.ibm.com ns2.softlayer.com - ns016.name.cloud.ibm.com You need to go back your Domain Registration sub-menu from the Classic Infrastructure menu Click on Add /Edit NS link of your domain and change the list of NameServers accordingly to the CIS demands. After a few minutes, you CIS instance will integrate your domain ( Active ). You need to redirect a subdomain such as www .greenv2.com to your Ingress Public IP address, create an 'A' entry just as shown below. Tick on proxy just as shown below to benefit from IBM CIS caching IBM Cloud Function IBM Cloud Certificate Manager needs a webhook to call on an event such as certificate expiration or certification renewal. This is done by calling a function, fortunately the IBM documentation points out a github link which shows a predefined piece of code in javascript to implement the integration between IBM Cloud Certificate Manager and IBM Cloud Function . The code used for greenv2 project is here . Here is a few screenshot that is not presented in the link when configuring the function especially regarding the parameters. iamApiKey The easiest way to have this one is to go the Access(IAM) menu And click on IBM Cloud API keys and then Create an IBM Cloud API key Provide a name an click on Create You will be given a one-time-only view of the key Copy and paste it to the iamApiKey parameter of the function. I might download it to a file to have a backup of the key somewhere else. IBM Cloud will never show that key again after closing this window. allowedCertificateManagerCRNs Actually, we skipped this one by commenting the first check in the main function. cisCrn This parameter may be retrieved in the overview of your CIS instance. cmRegion This parameter is used to determine the Region endpoint of your CIS. It should be : - eu-gb for London - eu-de for Francfort ... IBM Cloud Certificate Manager Create your IBM Cloud Certificate Manager instance here . Go to Notifications and Click on Add Notification Channel . Select Callback URL and paste to the Channel Endpoint the URL pasted from the function created (see below) and click on Save . You may click on Test connection to check if your URL is correct. Then go to Manage menu and click on Order Certificate Click on I'm using Cloud Internet Services Then, give it a name and choose the CIS instance and choose Wildcard certificate This will enable the certificate for all subdomain *.yourdomain.com . Click on Order . After a few seconds, you should have a valid certificate for 90 days.","title":"Certificates"},{"location":"CERTIFICATE-SETUP/#tls-certificate-setup","text":"Guide to all available configuration settings. Prerequesite : IBM Cloud Account","title":"TLS-CERTIFICATE Setup"},{"location":"CERTIFICATE-SETUP/#ibm-cloud-components-needed","text":"The project needs to have a secure website based on TLS encryption, hence https protocol is used, this latter needs a valid and up-to-date certificate. IBM Certificate Manager is used to store and to manage the certificate IBM Certificate Manager check expiration date and if needed call a webhook Function Service to renew the certificate A certificate is generated for a domain name, this one is handled by IBM Cloud Internet Service , the domain registrar is handle by IBM Cloud Domain Name Service .","title":"IBM Cloud Components needed"},{"location":"CERTIFICATE-SETUP/#ibm-cloud-domain-name-service","text":"You may register a new domain here . Click on CREATE . Provide a domain name, the price may change depending on the extension (.com, .net, .org, ...) and the number of years chosen. You may click on Check Availability to check whether or not the domain name provided is available. You may proceed by clicking on Continue if your domain name is available Fill up the form and take care about the email address which will be used to validate your purchase. Click on Order Now to validate the process. After clicking on the link in the mail sent to your mailbox, you should have valid domain name such as follows after a few minutes :","title":"IBM Cloud Domain Name Service"},{"location":"CERTIFICATE-SETUP/#ibm-cloud-internet-service-cis","text":"You may create an IBM CIS instance here . Click on CREATE . Click on Let's get started . Provided the domain name you created on the previous stage and Click on Connect and continue . The system will automatically detect the NameServers attached by default (your registrar setup) to your domain, and proposed a list of CIS NameServers to replace, for instance : ns1.softlayer.com - ns015.name.cloud.ibm.com ns2.softlayer.com - ns016.name.cloud.ibm.com You need to go back your Domain Registration sub-menu from the Classic Infrastructure menu Click on Add /Edit NS link of your domain and change the list of NameServers accordingly to the CIS demands. After a few minutes, you CIS instance will integrate your domain ( Active ). You need to redirect a subdomain such as www .greenv2.com to your Ingress Public IP address, create an 'A' entry just as shown below. Tick on proxy just as shown below to benefit from IBM CIS caching","title":"IBM Cloud Internet Service (CIS)"},{"location":"CERTIFICATE-SETUP/#ibm-cloud-function","text":"IBM Cloud Certificate Manager needs a webhook to call on an event such as certificate expiration or certification renewal. This is done by calling a function, fortunately the IBM documentation points out a github link which shows a predefined piece of code in javascript to implement the integration between IBM Cloud Certificate Manager and IBM Cloud Function . The code used for greenv2 project is here . Here is a few screenshot that is not presented in the link when configuring the function especially regarding the parameters. iamApiKey The easiest way to have this one is to go the Access(IAM) menu And click on IBM Cloud API keys and then Create an IBM Cloud API key Provide a name an click on Create You will be given a one-time-only view of the key Copy and paste it to the iamApiKey parameter of the function. I might download it to a file to have a backup of the key somewhere else. IBM Cloud will never show that key again after closing this window. allowedCertificateManagerCRNs Actually, we skipped this one by commenting the first check in the main function. cisCrn This parameter may be retrieved in the overview of your CIS instance. cmRegion This parameter is used to determine the Region endpoint of your CIS. It should be : - eu-gb for London - eu-de for Francfort ...","title":"IBM Cloud Function"},{"location":"CERTIFICATE-SETUP/#ibm-cloud-certificate-manager","text":"Create your IBM Cloud Certificate Manager instance here . Go to Notifications and Click on Add Notification Channel . Select Callback URL and paste to the Channel Endpoint the URL pasted from the function created (see below) and click on Save . You may click on Test connection to check if your URL is correct. Then go to Manage menu and click on Order Certificate Click on I'm using Cloud Internet Services Then, give it a name and choose the CIS instance and choose Wildcard certificate This will enable the certificate for all subdomain *.yourdomain.com . Click on Order . After a few seconds, you should have a valid certificate for 90 days.","title":"IBM Cloud Certificate Manager"},{"location":"CERTIFICATE-deploy/","text":"TLS-CERTIFICATE Deployment and Usage Guide to all available configuration settings. IBM Cloud Documentation reference This documentation is based on How to deploy a certificate to an IKS cluster in IBM Cloud documentation . You might have to update your laptop plugin first here . Step 1. Get your Certificate CRN Go back to your certificate Manager service and copy your Certificate CRN Step 2. Deploy your certificate to your IKS Cluster Connect to your IBM Cloud Account by issuing the following command and follow the instructions : ibmcloud login -a cloud.ibm.com -r region -sso where is eu-gb for London or eu-de for Francfort, ... Download the kubeconfig files for your cluster. Issue the following command : ibmcloud ks cluster-config --cluster Greenv2 where Greenv2 here is the name of your IKS cluster. You should have this message : The configuration for Greenv2 was downloaded successfully. Export environment variables to start using Kubernetes. export KUBECONFIG=/Users/vann/.bluemix/plugins/container-service/clusters/Greenv2/kube-config-lon02-Greenv2.yml Apply the last line export KUBECONFIG=... to make your IKS cluster your default context. Then you are set to deploy your TLS certificate to your IKS Cluster, Issue the following to deploy : ibmcloud ks alb-cert-deploy --cluster Greenv2 --secret-name tls-secret --cert-crn Certificate CRN . Where is the CRN you got from Step 1. above. and is the secret name in namespace ibm-cert-store and namespace default . Now, the secret is created in ibm-cert-store and default namespaces. Step 3. How to use your certificate when deploying your application Most details are described here . Step 4. How to update to a new certificate Simply issue the following command to update your secret when a new certificate has been re-issued. ibmcloud ks alb-cert-deploy --update --cluster Greenv2 --secret-name tls-secret --cert-crn Certificate CRN .","title":"TLS-CERTIFICATE Deployment and Usage"},{"location":"CERTIFICATE-deploy/#tls-certificate-deployment-and-usage","text":"Guide to all available configuration settings.","title":"TLS-CERTIFICATE Deployment and Usage"},{"location":"CERTIFICATE-deploy/#ibm-cloud-documentation-reference","text":"This documentation is based on How to deploy a certificate to an IKS cluster in IBM Cloud documentation . You might have to update your laptop plugin first here .","title":"IBM Cloud Documentation reference"},{"location":"CERTIFICATE-deploy/#step-1-get-your-certificate-crn","text":"Go back to your certificate Manager service and copy your Certificate CRN","title":"Step 1. Get your Certificate CRN"},{"location":"CERTIFICATE-deploy/#step-2-deploy-your-certificate-to-your-iks-cluster","text":"Connect to your IBM Cloud Account by issuing the following command and follow the instructions : ibmcloud login -a cloud.ibm.com -r region -sso where is eu-gb for London or eu-de for Francfort, ... Download the kubeconfig files for your cluster. Issue the following command : ibmcloud ks cluster-config --cluster Greenv2 where Greenv2 here is the name of your IKS cluster. You should have this message : The configuration for Greenv2 was downloaded successfully. Export environment variables to start using Kubernetes. export KUBECONFIG=/Users/vann/.bluemix/plugins/container-service/clusters/Greenv2/kube-config-lon02-Greenv2.yml Apply the last line export KUBECONFIG=... to make your IKS cluster your default context. Then you are set to deploy your TLS certificate to your IKS Cluster, Issue the following to deploy : ibmcloud ks alb-cert-deploy --cluster Greenv2 --secret-name tls-secret --cert-crn Certificate CRN . Where is the CRN you got from Step 1. above. and is the secret name in namespace ibm-cert-store and namespace default . Now, the secret is created in ibm-cert-store and default namespaces.","title":"Step 2. Deploy your certificate to your IKS Cluster"},{"location":"CERTIFICATE-deploy/#step-3-how-to-use-your-certificate-when-deploying-your-application","text":"Most details are described here .","title":"Step 3. How to use your certificate when deploying your application"},{"location":"CERTIFICATE-deploy/#step-4-how-to-update-to-a-new-certificate","text":"Simply issue the following command to update your secret when a new certificate has been re-issued. ibmcloud ks alb-cert-deploy --update --cluster Greenv2 --secret-name tls-secret --cert-crn Certificate CRN .","title":"Step 4. How to update to a new certificate"},{"location":"DEMO/","text":"Drupal sites on the IBM Container Service Guide to all available configuration settings. Preamble: Why Kubernetes? The shift towards cloud-native deployment models allows developers to package their applications consistently between staging and production, and helps them scale their deployments horizontally across a large pool of compute resources more quickly. In contrast to other cloud-native approaches - like Platform-as-a-Service with Heroku or Cloud Foundry - container orchestration system like Kubernetes are \"less-opinionated\" and offer a great amount of flexibility at the cost of a single prescribed set of guidelines, which can make them more attractive to those migrating from a virtual machine or bare metal approach rather than towards PaaS directly. What this MVP shows This MVP shows how one might migrate a traditional web-server, application-server, and database-server based application into a container-based model that depends on cloud services in order to speed application development by reducing time spent on managing servers across a large deployment target environment. Functional Drupal site running on the IBM Cloud Clearly defined and easy to implement process for pushing code updates Synchronize or migrate one database to another database Taking advantage of a continous integration pipeline 1. Functional Drupal site running on the IBM Cloud A managed Kubernetes cluster from the IBM Kubernetes Service provides the fabric on which to install a set of NGINX and PHP-FPM containers that run Drupal. These containers package custom site code and the underlying Kubernetes fabric can bind those containers to data services, load balancers, and storage volumes provided by the IBM Cloud. 1.1 Initial environment setup The initial setup instructions show how to set up a Kubernetes cluster and provision the MySQL, Redis, and Memcached services needed by the Drupal cluster. 1.2 First container cluster deployment Once the fabric and services are configured, you can build container images and deploy them to the IBM Container Service manually or through an automated pipeline. The container deployment instructions describe how. 1.3 Complete Drupal configuration Connecting to Drupal to finish installation. Once all of the containers have gotten to the Running state (you can see status with 'kubectl get pods') you can find the public IP of the Drupal cluster with kubectl get services . Because the settings.php file has been set up to get the MySQL connection information from the Kubernetes environment, it's a shorter process than normal. 2. Clearly defined and easy to implement process for pushing code updates Once the initial environment is set up, you can initiate additional build, test, and deploy workflows by committing code to specific folders in this repository. This simulates GitHub or BitBucket web hooks. 2.1 Updating the underlying NGINX and PHP container images You can commit updated NGINX or PHP version files to the config directory. This will in turn trigger base image rebuilds in the DevOps pipeline, and in turn rebuild custom Drupal-based code images on top and deploy them. 2.2 Updating custom code and triggering code layer rebuilds You can commit code that should be layered on top of base NGINX, PHP, and Drupal installation by changing code in the code directory. This will trigger a custom code rebuild and deploy. 3. Synchronize or migrate one database to another database Ongoing management of the Drupal cluster can be performed with arbitrary shell commands and drush commands invoked by logging into the PHP-CLI container. This container could also be extended to run arbitrary commands on startup through the DevOps pipeline. 3.1. Using the PHP CLI container to execute arbitrary commands You can exec into the PHP CLI container to run arbitrary bash or MySQL commands . 3.2. Using the PHP CLI container to execute migration commands You can exec into the PHP CLI container to run the transfer-data.sh and transfer-files.sh scripts injected from the code/drush directory . For example: kubectl exec ${PHP_CLI_CONTAINER_NAME} /root/drush/transfer-files.sh and kubectl exec ${PHP_CLI_CONTAINER_NAME} /root/drush/transfer-data.sh 3.3. Using a PHP FPM container to execute drush commands You can exec into the PHP FPM container to run the drush-status.sh script injected from the code/drush directory . For example: kubectl exec ${PHP_FPM_CONTAINER_NAME} /var/www/drupal/drush/drush-status.sh 4. Taking advantage of a continuous integration pipeline The pipeline setup instructions show how IBM DevOps can be used with user-defined scripts and webhooks to initiate build, test, and deployment flows. These can incorporate unit test scripts, security vulnerability assessments, and blue/green rolling deploys. These workflows can reuse build tool Docker images as well, which is a new feature of IBM DevOps services. 4.1. Checking in configuration or code updates Once configured, the pipeline will detect changes to the top level config and code directories and trigger new build and deploy processes depending on the change. 4.2 Synchronizing data from production to staging You can also use the pipeline UI to execute data and file synchronization. You can also set up arbitrary script execution by extending this model.","title":"Overview"},{"location":"DEMO/#drupal-sites-on-the-ibm-container-service","text":"Guide to all available configuration settings.","title":"Drupal sites on the IBM Container Service"},{"location":"DEMO/#preamble-why-kubernetes","text":"The shift towards cloud-native deployment models allows developers to package their applications consistently between staging and production, and helps them scale their deployments horizontally across a large pool of compute resources more quickly. In contrast to other cloud-native approaches - like Platform-as-a-Service with Heroku or Cloud Foundry - container orchestration system like Kubernetes are \"less-opinionated\" and offer a great amount of flexibility at the cost of a single prescribed set of guidelines, which can make them more attractive to those migrating from a virtual machine or bare metal approach rather than towards PaaS directly.","title":"Preamble: Why Kubernetes?"},{"location":"DEMO/#what-this-mvp-shows","text":"This MVP shows how one might migrate a traditional web-server, application-server, and database-server based application into a container-based model that depends on cloud services in order to speed application development by reducing time spent on managing servers across a large deployment target environment. Functional Drupal site running on the IBM Cloud Clearly defined and easy to implement process for pushing code updates Synchronize or migrate one database to another database Taking advantage of a continous integration pipeline","title":"What this MVP shows"},{"location":"DEMO/#1-functional-drupal-site-running-on-the-ibm-cloud","text":"A managed Kubernetes cluster from the IBM Kubernetes Service provides the fabric on which to install a set of NGINX and PHP-FPM containers that run Drupal. These containers package custom site code and the underlying Kubernetes fabric can bind those containers to data services, load balancers, and storage volumes provided by the IBM Cloud.","title":"1. Functional Drupal site running on the IBM Cloud"},{"location":"DEMO/#11-initial-environment-setup","text":"The initial setup instructions show how to set up a Kubernetes cluster and provision the MySQL, Redis, and Memcached services needed by the Drupal cluster.","title":"1.1 Initial environment setup"},{"location":"DEMO/#12-first-container-cluster-deployment","text":"Once the fabric and services are configured, you can build container images and deploy them to the IBM Container Service manually or through an automated pipeline. The container deployment instructions describe how.","title":"1.2 First container cluster deployment"},{"location":"DEMO/#13-complete-drupal-configuration","text":"Connecting to Drupal to finish installation. Once all of the containers have gotten to the Running state (you can see status with 'kubectl get pods') you can find the public IP of the Drupal cluster with kubectl get services . Because the settings.php file has been set up to get the MySQL connection information from the Kubernetes environment, it's a shorter process than normal.","title":"1.3 Complete Drupal configuration"},{"location":"DEMO/#2-clearly-defined-and-easy-to-implement-process-for-pushing-code-updates","text":"Once the initial environment is set up, you can initiate additional build, test, and deploy workflows by committing code to specific folders in this repository. This simulates GitHub or BitBucket web hooks.","title":"2. Clearly defined and easy to implement process for pushing code updates"},{"location":"DEMO/#21-updating-the-underlying-nginx-and-php-container-images","text":"You can commit updated NGINX or PHP version files to the config directory. This will in turn trigger base image rebuilds in the DevOps pipeline, and in turn rebuild custom Drupal-based code images on top and deploy them.","title":"2.1 Updating the underlying NGINX and PHP container images"},{"location":"DEMO/#22-updating-custom-code-and-triggering-code-layer-rebuilds","text":"You can commit code that should be layered on top of base NGINX, PHP, and Drupal installation by changing code in the code directory. This will trigger a custom code rebuild and deploy.","title":"2.2 Updating custom code and triggering code layer rebuilds"},{"location":"DEMO/#3-synchronize-or-migrate-one-database-to-another-database","text":"Ongoing management of the Drupal cluster can be performed with arbitrary shell commands and drush commands invoked by logging into the PHP-CLI container. This container could also be extended to run arbitrary commands on startup through the DevOps pipeline.","title":"3. Synchronize or migrate one database to another database"},{"location":"DEMO/#31-using-the-php-cli-container-to-execute-arbitrary-commands","text":"You can exec into the PHP CLI container to run arbitrary bash or MySQL commands .","title":"3.1. Using the PHP CLI container to execute arbitrary commands"},{"location":"DEMO/#32-using-the-php-cli-container-to-execute-migration-commands","text":"You can exec into the PHP CLI container to run the transfer-data.sh and transfer-files.sh scripts injected from the code/drush directory . For example: kubectl exec ${PHP_CLI_CONTAINER_NAME} /root/drush/transfer-files.sh and kubectl exec ${PHP_CLI_CONTAINER_NAME} /root/drush/transfer-data.sh","title":"3.2. Using the PHP CLI container to execute migration commands"},{"location":"DEMO/#33-using-a-php-fpm-container-to-execute-drush-commands","text":"You can exec into the PHP FPM container to run the drush-status.sh script injected from the code/drush directory . For example: kubectl exec ${PHP_FPM_CONTAINER_NAME} /var/www/drupal/drush/drush-status.sh","title":"3.3. Using a PHP FPM container to execute drush commands"},{"location":"DEMO/#4-taking-advantage-of-a-continuous-integration-pipeline","text":"The pipeline setup instructions show how IBM DevOps can be used with user-defined scripts and webhooks to initiate build, test, and deployment flows. These can incorporate unit test scripts, security vulnerability assessments, and blue/green rolling deploys. These workflows can reuse build tool Docker images as well, which is a new feature of IBM DevOps services.","title":"4. Taking advantage of a continuous integration pipeline"},{"location":"DEMO/#41-checking-in-configuration-or-code-updates","text":"Once configured, the pipeline will detect changes to the top level config and code directories and trigger new build and deploy processes depending on the change.","title":"4.1. Checking in configuration or code updates"},{"location":"DEMO/#42-synchronizing-data-from-production-to-staging","text":"You can also use the pipeline UI to execute data and file synchronization. You can also set up arbitrary script execution by extending this model.","title":"4.2 Synchronizing data from production to staging"},{"location":"DEPLOY-CONTAINERS/","text":"Building and deploying the initial set of containers Now that the Kubernetes cluster and MySQL, Redis, and Memcached services have been provisioned, it's time to start a set of containers (pods) on the Kubernetes worker nodes. We do this through a set of declarative YAML files, which define not only the containers to start, but the storage and network configuration that they depend on. Review the Docker build files There are 6 Docker images, 3 for base configuration and 3 custom code which build upon the base configuration. The first set of three (NGINX, PHP-FPM, and PHP-CLI) provide the underlying web server and PHP environment needed by Drupal. These are rebuilt based on new version numbers provided in text files in the config directory, which in turn triggers a rebuild of the second set of three code images. The scripts/docker/config-nginx/Dockerfile provides a base level of NGINX configured to delegate PHP requests to PHP-FPM. The scripts/docker/config-php-fpm/Dockerfile provides a base level of operating system packages with PHP-FPM and extensions. The scripts/docker/config-php-cli/Dockerfile provides a base level of OS packages with PHP-CLI and extensions. The second set of three (NGINX, PHP-FPM, and PHP-CLI) provide image builds specific to Drupal, Drush, and custom code that is pushed to the code directory. They are rebuilt when anything in that directory changes. The scripts/docker/code-nginx/Dockerfile builds on the base image and adds static code to the /var/www/html directory. The scripts/docker/code-php-fpm/Dockerfile installs Drupal via Composer, then copies over custom code. It also mounts and configures the volume needed at runtime through its start.sh script. The scripts/docker/code-php-cli/Dockerfile installs Drush via Composer, then copies over custom code. It also mounts and configures both the staging and production volumes needed at runtime through its start.sh script. Review the Kubernetes container deployment configuration files The Kubernetes deployment files instantiate containers based on the code images (never just the config images). We set up two container clusters, one for a \"Staging\" environment and one for a \"Production\" environment. They share the same base Docker images. The scripts/kubernetes/persistent-volumes.yaml files defines two 20 GB storage volumes (one for staging, one for production) that can be mounted by many containers ( ReadWriteMany ). The containers then reference these volumes in their own configuration files. The scripts/kubernetes/php-fpm-stg.yaml and scripts/kubernetes/php-fpm-prd.yaml files describe the pod/deployment for the PHP-FPM containers in each environment. They specify how many containers from the given image and tag to start, what port to listen on, the environment variables that map to the service credentials, and where to mount the storage volume. Similarly, the scripts/kubernetes/nginx-stg.yaml and scripts/kubernetes/nginx-prd.yaml files describe the pod/deployment for the NGINX containers. They specify how many containers from the given image and tag to start (1, for now), what port to listen on, what IP address to bind to, the environment variables that map to the service credentials, and where to mount the storage volume. Finally, the scripts/kubernetes/php-cli.yaml configures the single shared CLI container that is used to manage files and data from both environments and synchronize data ( code/drush/transfer-data.sh ) and files ( code/drush/transfer-files.sh ) from production to staging. Build container images and push to the private registry If you haven't already installed the Container Service plugin for the ibmcloud CLI you installed when setting up the Kubernetes clusters, do it now: # Configure the plugin if you haven't yet ibmcloud plugin install container-service -r Bluemix ibmcloud login -a https://api.ng.bluemix.net ibmcloud cs init Next, list the clusters already provisioned on IBM Cloud, and get the Kubernetes configuration information. ibmcloud cs clusters # Find your cluster, and input into next command ibmcloud cs cluster-config $CLUSTER_NAME Copy the export line from the previous command to configure kubectl to point to your cluster. # Configure kubectl export KUBECONFIG=/Users/$USER_HOME_DIR/.bluemix/plugins/container-service/clusters/$CLUSTER_NAME/kube-config-$DATA_CENTER-$CLUSTER_NAME.yml Finally, test your connection by interacting with your cluster. # Confirm cluster is ready kubectl get nodes # Run the visual dashboard proxy and open it with a browser on your workstation at http://127.0.0.1:8001/ui kubectl proxy Configure your namespace The Dockerfiles in this repo are hardcoded to the orod image registry namespace. You need to create your own namespace and update the deployment manifests that reference images. Install the IBM Cloud Container Registry CLI plugin: ibmcloud plugin install container-registry -r Bluemix ibmcloud login -a https://api.ng.bluemix.net Create a namespace: ibmcloud cr namespace-add $MY_NAMESPACE ibmcloud cr namespaces # List namespaces ibmcloud cr login # To enable pushing images Configure scripts with your namespace. You will need to replace orod in - build-containers.sh - php-cli.yaml - nginx-stg.yaml - php-fpm-stg.yaml - nginx-prd.yaml - php-fpm-prd.yaml Finally, you may have to create an imagePull token that allows your container cluster to access images in your private container registry. Build the container images Run this script to build the containers and push them to your registry: cd scripts/pipeline ./build-on-config-change.sh Deploy the container images to the Kubernetes cluster # Create an image pull token for the given registry. The kubectl command doesn't like the backslashed wrapped lines presented here for readability, so change it all to one line before you run. ibmcloud cr token-list ibmcloud cr token-get $TOKEN_ID kubectl --namespace default create secret docker-registry image-pull \\ --docker-server= registry.ng.bluemix.net \\ --docker-username= token \\ --docker-password= ${TOKEN} \\ --docker-email= ${YOUR_EMAIL} ./rolling-code-deploy.sh The YAML files in this directory reference the same image names (including the name of our registry namespace) as in the build-on-config-change.sh script. These is the hand-off point between image build/push, and Kubernetes deploy. Specify a non-floating LoadBalancer IP Obtain the available IPs assigned to your cluster (look for \"is_public: true\") kubectl get cm ibm-cloud-provider-vlan-ip-config -n kube-system -o yaml Set an IP address for Staging and Production in the spec.loadBalancerIP value inside scripts/kubernetes/nginx-prd.yaml and scripts/kubernetes/nginx-stg.yaml . For example: apiVersion: v1 kind: Service metadata: name: nginx-prd spec: loadBalancerIP: $IP ... --- Setup Ingress (replaces LoadBalancer) So far, we have configured LoadBalancer as the service type for the \"nginx-prd\" service. We can use the Ingress type instead to give us more flexibility with specifying routes from a single endpoint and also us to use a hostname instead of floating IPs to access our application. Detailed docs here: https://console.bluemix.net/docs/containers/cs_apps.html#cs_apps_public_ingress. 1) Remove the type: LoadBalancer line from scripts/kubernetes/nginx.yaml 2) Obtain your \"Ingress subdomain\". ibmcloud cs cluster-get $CLUSTER_NAME 3) Edit scripts/kubernetes/ingress/ingress.yaml to include your subdomain. 4) Redeploy your \"nginx-prd\" service kubectl delete service nginx-prd kubectl apply -f scripts/kubernetes/nginx-prd.yaml 5) Deploy the ingress service kubectl apply -f scripts/kubernetes/ingress/ingress.yaml 6) Once ingress is up (may take a minute), access your application via your domain. Tear down the containers If you want to cleanly install the environment, for example to push a new set of container versions, use the following script: cd scripts/pipeline ./rolling-code-deploy.sh","title":"Deployment"},{"location":"DEPLOY-CONTAINERS/#building-and-deploying-the-initial-set-of-containers","text":"Now that the Kubernetes cluster and MySQL, Redis, and Memcached services have been provisioned, it's time to start a set of containers (pods) on the Kubernetes worker nodes. We do this through a set of declarative YAML files, which define not only the containers to start, but the storage and network configuration that they depend on.","title":"Building and deploying the initial set of containers"},{"location":"DEPLOY-CONTAINERS/#review-the-docker-build-files","text":"There are 6 Docker images, 3 for base configuration and 3 custom code which build upon the base configuration. The first set of three (NGINX, PHP-FPM, and PHP-CLI) provide the underlying web server and PHP environment needed by Drupal. These are rebuilt based on new version numbers provided in text files in the config directory, which in turn triggers a rebuild of the second set of three code images. The scripts/docker/config-nginx/Dockerfile provides a base level of NGINX configured to delegate PHP requests to PHP-FPM. The scripts/docker/config-php-fpm/Dockerfile provides a base level of operating system packages with PHP-FPM and extensions. The scripts/docker/config-php-cli/Dockerfile provides a base level of OS packages with PHP-CLI and extensions. The second set of three (NGINX, PHP-FPM, and PHP-CLI) provide image builds specific to Drupal, Drush, and custom code that is pushed to the code directory. They are rebuilt when anything in that directory changes. The scripts/docker/code-nginx/Dockerfile builds on the base image and adds static code to the /var/www/html directory. The scripts/docker/code-php-fpm/Dockerfile installs Drupal via Composer, then copies over custom code. It also mounts and configures the volume needed at runtime through its start.sh script. The scripts/docker/code-php-cli/Dockerfile installs Drush via Composer, then copies over custom code. It also mounts and configures both the staging and production volumes needed at runtime through its start.sh script.","title":"Review the Docker build files"},{"location":"DEPLOY-CONTAINERS/#review-the-kubernetes-container-deployment-configuration-files","text":"The Kubernetes deployment files instantiate containers based on the code images (never just the config images). We set up two container clusters, one for a \"Staging\" environment and one for a \"Production\" environment. They share the same base Docker images. The scripts/kubernetes/persistent-volumes.yaml files defines two 20 GB storage volumes (one for staging, one for production) that can be mounted by many containers ( ReadWriteMany ). The containers then reference these volumes in their own configuration files. The scripts/kubernetes/php-fpm-stg.yaml and scripts/kubernetes/php-fpm-prd.yaml files describe the pod/deployment for the PHP-FPM containers in each environment. They specify how many containers from the given image and tag to start, what port to listen on, the environment variables that map to the service credentials, and where to mount the storage volume. Similarly, the scripts/kubernetes/nginx-stg.yaml and scripts/kubernetes/nginx-prd.yaml files describe the pod/deployment for the NGINX containers. They specify how many containers from the given image and tag to start (1, for now), what port to listen on, what IP address to bind to, the environment variables that map to the service credentials, and where to mount the storage volume. Finally, the scripts/kubernetes/php-cli.yaml configures the single shared CLI container that is used to manage files and data from both environments and synchronize data ( code/drush/transfer-data.sh ) and files ( code/drush/transfer-files.sh ) from production to staging.","title":"Review the Kubernetes container deployment configuration files"},{"location":"DEPLOY-CONTAINERS/#build-container-images-and-push-to-the-private-registry","text":"If you haven't already installed the Container Service plugin for the ibmcloud CLI you installed when setting up the Kubernetes clusters, do it now: # Configure the plugin if you haven't yet ibmcloud plugin install container-service -r Bluemix ibmcloud login -a https://api.ng.bluemix.net ibmcloud cs init Next, list the clusters already provisioned on IBM Cloud, and get the Kubernetes configuration information. ibmcloud cs clusters # Find your cluster, and input into next command ibmcloud cs cluster-config $CLUSTER_NAME Copy the export line from the previous command to configure kubectl to point to your cluster. # Configure kubectl export KUBECONFIG=/Users/$USER_HOME_DIR/.bluemix/plugins/container-service/clusters/$CLUSTER_NAME/kube-config-$DATA_CENTER-$CLUSTER_NAME.yml Finally, test your connection by interacting with your cluster. # Confirm cluster is ready kubectl get nodes # Run the visual dashboard proxy and open it with a browser on your workstation at http://127.0.0.1:8001/ui kubectl proxy","title":"Build container images and push to the private registry"},{"location":"DEPLOY-CONTAINERS/#configure-your-namespace","text":"The Dockerfiles in this repo are hardcoded to the orod image registry namespace. You need to create your own namespace and update the deployment manifests that reference images. Install the IBM Cloud Container Registry CLI plugin: ibmcloud plugin install container-registry -r Bluemix ibmcloud login -a https://api.ng.bluemix.net Create a namespace: ibmcloud cr namespace-add $MY_NAMESPACE ibmcloud cr namespaces # List namespaces ibmcloud cr login # To enable pushing images Configure scripts with your namespace. You will need to replace orod in - build-containers.sh - php-cli.yaml - nginx-stg.yaml - php-fpm-stg.yaml - nginx-prd.yaml - php-fpm-prd.yaml Finally, you may have to create an imagePull token that allows your container cluster to access images in your private container registry.","title":"Configure your namespace"},{"location":"DEPLOY-CONTAINERS/#build-the-container-images","text":"Run this script to build the containers and push them to your registry: cd scripts/pipeline ./build-on-config-change.sh","title":"Build the container images"},{"location":"DEPLOY-CONTAINERS/#deploy-the-container-images-to-the-kubernetes-cluster","text":"# Create an image pull token for the given registry. The kubectl command doesn't like the backslashed wrapped lines presented here for readability, so change it all to one line before you run. ibmcloud cr token-list ibmcloud cr token-get $TOKEN_ID kubectl --namespace default create secret docker-registry image-pull \\ --docker-server= registry.ng.bluemix.net \\ --docker-username= token \\ --docker-password= ${TOKEN} \\ --docker-email= ${YOUR_EMAIL} ./rolling-code-deploy.sh The YAML files in this directory reference the same image names (including the name of our registry namespace) as in the build-on-config-change.sh script. These is the hand-off point between image build/push, and Kubernetes deploy.","title":"Deploy the container images to the Kubernetes cluster"},{"location":"DEPLOY-CONTAINERS/#specify-a-non-floating-loadbalancer-ip","text":"Obtain the available IPs assigned to your cluster (look for \"is_public: true\") kubectl get cm ibm-cloud-provider-vlan-ip-config -n kube-system -o yaml Set an IP address for Staging and Production in the spec.loadBalancerIP value inside scripts/kubernetes/nginx-prd.yaml and scripts/kubernetes/nginx-stg.yaml . For example: apiVersion: v1 kind: Service metadata: name: nginx-prd spec: loadBalancerIP: $IP ... ---","title":"Specify a non-floating LoadBalancer IP"},{"location":"DEPLOY-CONTAINERS/#setup-ingress-replaces-loadbalancer","text":"So far, we have configured LoadBalancer as the service type for the \"nginx-prd\" service. We can use the Ingress type instead to give us more flexibility with specifying routes from a single endpoint and also us to use a hostname instead of floating IPs to access our application. Detailed docs here: https://console.bluemix.net/docs/containers/cs_apps.html#cs_apps_public_ingress. 1) Remove the type: LoadBalancer line from scripts/kubernetes/nginx.yaml 2) Obtain your \"Ingress subdomain\". ibmcloud cs cluster-get $CLUSTER_NAME 3) Edit scripts/kubernetes/ingress/ingress.yaml to include your subdomain. 4) Redeploy your \"nginx-prd\" service kubectl delete service nginx-prd kubectl apply -f scripts/kubernetes/nginx-prd.yaml 5) Deploy the ingress service kubectl apply -f scripts/kubernetes/ingress/ingress.yaml 6) Once ingress is up (may take a minute), access your application via your domain.","title":"Setup Ingress (replaces LoadBalancer)"},{"location":"DEPLOY-CONTAINERS/#tear-down-the-containers","text":"If you want to cleanly install the environment, for example to push a new set of container versions, use the following script: cd scripts/pipeline ./rolling-code-deploy.sh","title":"Tear down the containers"},{"location":"Drupal-Cloud-Object-Storage/","text":"Drupal on IBM Cloud Object Storage Guide to all available configuration settings. IKS integration with IBM Cloud Object Storage Follow the instructions in this link to setup your IKS instance This documentation will essential create all the needed storageClass in your IKS instance to address all kind of IBM Cloud Object Storage offerings. At the end of the procedure, you will have this : kubernetes$ kubectl get storageClass NAME PROVISIONER AGE default ibm.io/ibmc-file 27d ibmc-file-bronze (default) ibm.io/ibmc-file 27d ibmc-file-custom ibm.io/ibmc-file 27d ibmc-file-gold ibm.io/ibmc-file 27d ibmc-file-retain-bronze ibm.io/ibmc-file 27d ibmc-file-retain-custom ibm.io/ibmc-file 27d ibmc-file-retain-gold ibm.io/ibmc-file 27d ibmc-file-retain-silver ibm.io/ibmc-file 27d ibmc-file-silver ibm.io/ibmc-file 27d ibmc-s3fs-cold-cross-region ibm.io/ibmc-s3fs 23h ibmc-s3fs-cold-regional ibm.io/ibmc-s3fs 23h ibmc-s3fs-flex-cross-region ibm.io/ibmc-s3fs 23h ibmc-s3fs-flex-perf-cross-region ibm.io/ibmc-s3fs 23h ibmc-s3fs-flex-perf-regional ibm.io/ibmc-s3fs 23h ibmc-s3fs-flex-regional ibm.io/ibmc-s3fs 23h ibmc-s3fs-standard-cross-region ibm.io/ibmc-s3fs 23h ibmc-s3fs-standard-perf-cross-region ibm.io/ibmc-s3fs 23h ibmc-s3fs-standard-perf-regional ibm.io/ibmc-s3fs 23h ibmc-s3fs-standard-regional ibm.io/ibmc-s3fs 23h ibmc-s3fs-vault-cross-region ibm.io/ibmc-s3fs 23h ibmc-s3fs-vault-regional ibm.io/ibmc-s3fs 23h Focusing on ibmc-s3fs- XXXX -\\ perf-> YYYY storage classes only : XXXX : standard , vault , cold , flex are the four IBM COS storage offering. standard : this option should be used when few data are stored especially for development environment or even for some AI usage when the overall data is read many times. cold : this option should be used when few data reads occurred (actually less than 14% of total storage per month) especially for archives or backups. vault : is a trade-off between standard and cold (more than 14% and less than 100% of total storage reads per month) flex : this option should be used when the client do not know how its data are used, the costs are eventually capped if necessary Optional perf value means the usage of IBM Aspera to boost your data transfer. This is especially efficient on bad public network. YYYY : cross-region , regional determined the resiliency of the data, cross-region is at the regional failure level, regional is at the Availability Zone failure level. cross-region : give the ability for all of our custumers to retrieve a hundred percent of their data even of any regional breakdown (even if a whole region is burnt to the ground). In Europe, IBM Cloud Object Storage Cross Region offering is spread into Amsterdam, Francfort and Milan datacenters. regional : give the ability for all of our custumers to retrieve a hundred percent of their data even of any availability zone breakdown (even if a whole region is burnt to the ground). In Europe, IBM Cloud Object Storage Regional offering is either London or Francfort MZR (Multi-Zone Region). These storage classes may be used in your kubernetes instance Persistence Volume Claim (PVC) , you don't need to create a Persistance Volume , this latter is automatically created when a PVC of these ibmc-s3fs-XXXX-YYYY types are created. When deleting a PVC, the PV is also deleted automatically as well. IBM Cloud Object Storage usage in Drupal container Kubernetes secret to connect to IBM Cloud account Before creating your kubernetes PVC, you need to create a kubernete secret, so that the ibmc-s3fs-XXXX-YYYY storage class driver is able to connect to the right IBM Cloud account. You may use either a combination of ( API Key + COS ID instance ) or the standard S3 combination ( access key id + secret access key ). The first one allows you to have more control on privileges because it is based on IAM . Here is an exemple of the kubectl command to create the secret based on the standard S3 combination : kubectl create secret generic secret_name --type=ibm/ibmc-s3fs --from-literal=access-key= access_key_id --from-literal=secret-key= secret_access_key secret_name : specify a secret name access_key_id : provide the hmac access_key_id value secret_access_key : provide the hmac secret_access_key value How to get those details from IBM COS ? Create your IBM Cloud Object Storage instance Search in the IBM Cloud catalog this item and click on it. Provide a name , a resource group , choose the standard plan and click on create Go to Service credentials and click on new credential Provide a name , choose writer role, tick on Include HMAC credential {\"HMAC\":true} appears in the optional parameters pane, then click add Click on View credentials You may now copied either the apikey or the couple access_key_id/secret_access_key . In our example above, we use this latter. Kubernetes ClusterRole for IBM Cloud Object Storage Driver You need to create a Kubernetes ClusterRole named ibmcloud-object-storage-secret-reader including your secret Here is the yaml file needed : kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: ibmcloud-object-storage-secret-reader rules: - apiGroups: [ ] resources: [ secrets ] resourceNames: [ secret_name ] verbs: [ get ] Put your secret name in the resourceNames, you may put a list of secret names if needed. Create a Kubernetes PVC You may now be able to create a Kubernetes PVC based on IBM Cloud Object Storage bucket. Use the following yaml file to create your Kubernetes PVC : --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: pvc name annotations: ibm.io/auto-create-bucket: true ibm.io/auto-delete-bucket: false ibm.io/bucket: bucket name ibm.io/secret-name: secret name ibm.io/endpoint: https://s3.private.eu-gb.cloud-object-storage.appdomain.cloud spec: accessModes: - ReadWriteMany storageClassName: ibmc-s3fs-standard-regional resources: requests: storage: 100Gi # could be any number pvc name: provide your Kubernetes PVC name here in order to claim it in a pod bucket name: provide a bucket name, this bucket will appear in your IBM Cloud COS instance. Choose a long name because it has to be unique within all the existing bucket of the same region (including all other client buckets) secret name : provide your secret name you created before. Notice that the size of the storage is compulsory but its value has no sense, as the IBM Cloud COS bucket has no volume limitation. FI : a bucket may have up to 2^128 objects and an object may be up to 10 TB size. You may check your IBM Cloud COS PVC kubernetes$ kubectl get pvc | grep ibmc-s3fs sites-prd-pvc-cos Bound pvc-24323d88-a7a6-11e9-9ed4-6657bd2680ff 100Gi RWX ibmc-s3fs-standard-regional 23h sites-stg-pvc-cos Bound pvc-24298a3a-a7a6-11e9-9ed4-6657bd2680ff 100Gi RWX ibmc-s3fs-standard-regional 23h Use your Kubernetes PVC in your Kubernetes Drupal pod Specify a mount path in your pod spec: volumeMounts: - mountPath: /var/www/drupal/web/sites/default name: sites-cos-storage readOnly: false And specify you PVC name volumes: - name: sites-cos-storage persistentVolumeClaim: claimName: pvc name Actually, the Drupal container try at startup to change the owner of the /var/www/drupal/web/sites/default/files directory. thus the files sub directory should exist before this action, otherwise the container will fail. You need then to initiate an initContainer who mount the same directory and create the files sub directory in the event this one do not exist. initContainers: - image: uk.icr.io/greenv2-ns/code-php-fpm:latest volumeMounts: - mountPath: /var/www/drupal/web/sites/default name: sites-cos-storage readOnly: false name: create-files command: [ sh , -c , mkdir -p /var/www/drupal/web/sites/default/files ] securityContext: runAsUser: 0 Then any file or diretory created in the /var/www/drupal/web/sites/default sub directory will create an object in the specified IBM COS bucket Here is an example of two PVC created which trigger the create of two buckets: The following example shows how COS is organized via the ibmc-s3fs driver: root@php-fpm-stg-d5bb47bfb-j6hqk:/var/www/drupal/web/sites/default# ls -lR .: total 1 drwxrwxrwx 1 www-data www-data 0 Jul 17 10:19 files ./files: total 1 drwxr-xr-x 1 root root 0 Jul 17 10:20 dir1 drwxr-xr-x 1 root root 0 Jul 17 10:21 dir2 ./files/dir1: total 1 -rw-r--r-- 1 root root 7 Jul 17 10:21 myfile1 ./files/dir2: total 1 -rw-r--r-- 1 root root 7 Jul 17 10:21 myfile2 Each directory (files, dir1, dir2) has an entry in the bucket Each file (myfile1, myfile2) has also an entry in the bucket","title":"Cloud Object Storage"},{"location":"Drupal-Cloud-Object-Storage/#drupal-on-ibm-cloud-object-storage","text":"Guide to all available configuration settings.","title":"Drupal on IBM Cloud Object Storage"},{"location":"Drupal-Cloud-Object-Storage/#iks-integration-with-ibm-cloud-object-storage","text":"Follow the instructions in this link to setup your IKS instance This documentation will essential create all the needed storageClass in your IKS instance to address all kind of IBM Cloud Object Storage offerings. At the end of the procedure, you will have this : kubernetes$ kubectl get storageClass NAME PROVISIONER AGE default ibm.io/ibmc-file 27d ibmc-file-bronze (default) ibm.io/ibmc-file 27d ibmc-file-custom ibm.io/ibmc-file 27d ibmc-file-gold ibm.io/ibmc-file 27d ibmc-file-retain-bronze ibm.io/ibmc-file 27d ibmc-file-retain-custom ibm.io/ibmc-file 27d ibmc-file-retain-gold ibm.io/ibmc-file 27d ibmc-file-retain-silver ibm.io/ibmc-file 27d ibmc-file-silver ibm.io/ibmc-file 27d ibmc-s3fs-cold-cross-region ibm.io/ibmc-s3fs 23h ibmc-s3fs-cold-regional ibm.io/ibmc-s3fs 23h ibmc-s3fs-flex-cross-region ibm.io/ibmc-s3fs 23h ibmc-s3fs-flex-perf-cross-region ibm.io/ibmc-s3fs 23h ibmc-s3fs-flex-perf-regional ibm.io/ibmc-s3fs 23h ibmc-s3fs-flex-regional ibm.io/ibmc-s3fs 23h ibmc-s3fs-standard-cross-region ibm.io/ibmc-s3fs 23h ibmc-s3fs-standard-perf-cross-region ibm.io/ibmc-s3fs 23h ibmc-s3fs-standard-perf-regional ibm.io/ibmc-s3fs 23h ibmc-s3fs-standard-regional ibm.io/ibmc-s3fs 23h ibmc-s3fs-vault-cross-region ibm.io/ibmc-s3fs 23h ibmc-s3fs-vault-regional ibm.io/ibmc-s3fs 23h Focusing on ibmc-s3fs- XXXX -\\ perf-> YYYY storage classes only : XXXX : standard , vault , cold , flex are the four IBM COS storage offering. standard : this option should be used when few data are stored especially for development environment or even for some AI usage when the overall data is read many times. cold : this option should be used when few data reads occurred (actually less than 14% of total storage per month) especially for archives or backups. vault : is a trade-off between standard and cold (more than 14% and less than 100% of total storage reads per month) flex : this option should be used when the client do not know how its data are used, the costs are eventually capped if necessary Optional perf value means the usage of IBM Aspera to boost your data transfer. This is especially efficient on bad public network. YYYY : cross-region , regional determined the resiliency of the data, cross-region is at the regional failure level, regional is at the Availability Zone failure level. cross-region : give the ability for all of our custumers to retrieve a hundred percent of their data even of any regional breakdown (even if a whole region is burnt to the ground). In Europe, IBM Cloud Object Storage Cross Region offering is spread into Amsterdam, Francfort and Milan datacenters. regional : give the ability for all of our custumers to retrieve a hundred percent of their data even of any availability zone breakdown (even if a whole region is burnt to the ground). In Europe, IBM Cloud Object Storage Regional offering is either London or Francfort MZR (Multi-Zone Region). These storage classes may be used in your kubernetes instance Persistence Volume Claim (PVC) , you don't need to create a Persistance Volume , this latter is automatically created when a PVC of these ibmc-s3fs-XXXX-YYYY types are created. When deleting a PVC, the PV is also deleted automatically as well.","title":"IKS integration with IBM Cloud Object Storage"},{"location":"Drupal-Cloud-Object-Storage/#ibm-cloud-object-storage-usage-in-drupal-container","text":"","title":"IBM Cloud Object Storage usage in Drupal container"},{"location":"Drupal-Cloud-Object-Storage/#kubernetes-secret-to-connect-to-ibm-cloud-account","text":"Before creating your kubernetes PVC, you need to create a kubernete secret, so that the ibmc-s3fs-XXXX-YYYY storage class driver is able to connect to the right IBM Cloud account. You may use either a combination of ( API Key + COS ID instance ) or the standard S3 combination ( access key id + secret access key ). The first one allows you to have more control on privileges because it is based on IAM . Here is an exemple of the kubectl command to create the secret based on the standard S3 combination : kubectl create secret generic secret_name --type=ibm/ibmc-s3fs --from-literal=access-key= access_key_id --from-literal=secret-key= secret_access_key secret_name : specify a secret name access_key_id : provide the hmac access_key_id value secret_access_key : provide the hmac secret_access_key value","title":"Kubernetes secret to connect to IBM Cloud account"},{"location":"Drupal-Cloud-Object-Storage/#how-to-get-those-details-from-ibm-cos","text":"","title":"How to get those details from IBM COS ?"},{"location":"Drupal-Cloud-Object-Storage/#create-your-ibm-cloud-object-storage-instance","text":"Search in the IBM Cloud catalog this item and click on it. Provide a name , a resource group , choose the standard plan and click on create Go to Service credentials and click on new credential Provide a name , choose writer role, tick on Include HMAC credential {\"HMAC\":true} appears in the optional parameters pane, then click add Click on View credentials You may now copied either the apikey or the couple access_key_id/secret_access_key . In our example above, we use this latter.","title":"Create your IBM Cloud Object Storage instance"},{"location":"Drupal-Cloud-Object-Storage/#kubernetes-clusterrole-for-ibm-cloud-object-storage-driver","text":"You need to create a Kubernetes ClusterRole named ibmcloud-object-storage-secret-reader including your secret Here is the yaml file needed : kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: ibmcloud-object-storage-secret-reader rules: - apiGroups: [ ] resources: [ secrets ] resourceNames: [ secret_name ] verbs: [ get ] Put your secret name in the resourceNames, you may put a list of secret names if needed.","title":"Kubernetes ClusterRole for IBM Cloud Object Storage Driver"},{"location":"Drupal-Cloud-Object-Storage/#create-a-kubernetes-pvc","text":"You may now be able to create a Kubernetes PVC based on IBM Cloud Object Storage bucket. Use the following yaml file to create your Kubernetes PVC : --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: pvc name annotations: ibm.io/auto-create-bucket: true ibm.io/auto-delete-bucket: false ibm.io/bucket: bucket name ibm.io/secret-name: secret name ibm.io/endpoint: https://s3.private.eu-gb.cloud-object-storage.appdomain.cloud spec: accessModes: - ReadWriteMany storageClassName: ibmc-s3fs-standard-regional resources: requests: storage: 100Gi # could be any number pvc name: provide your Kubernetes PVC name here in order to claim it in a pod bucket name: provide a bucket name, this bucket will appear in your IBM Cloud COS instance. Choose a long name because it has to be unique within all the existing bucket of the same region (including all other client buckets) secret name : provide your secret name you created before. Notice that the size of the storage is compulsory but its value has no sense, as the IBM Cloud COS bucket has no volume limitation. FI : a bucket may have up to 2^128 objects and an object may be up to 10 TB size. You may check your IBM Cloud COS PVC kubernetes$ kubectl get pvc | grep ibmc-s3fs sites-prd-pvc-cos Bound pvc-24323d88-a7a6-11e9-9ed4-6657bd2680ff 100Gi RWX ibmc-s3fs-standard-regional 23h sites-stg-pvc-cos Bound pvc-24298a3a-a7a6-11e9-9ed4-6657bd2680ff 100Gi RWX ibmc-s3fs-standard-regional 23h","title":"Create a Kubernetes PVC"},{"location":"Drupal-Cloud-Object-Storage/#use-your-kubernetes-pvc-in-your-kubernetes-drupal-pod","text":"Specify a mount path in your pod spec: volumeMounts: - mountPath: /var/www/drupal/web/sites/default name: sites-cos-storage readOnly: false And specify you PVC name volumes: - name: sites-cos-storage persistentVolumeClaim: claimName: pvc name Actually, the Drupal container try at startup to change the owner of the /var/www/drupal/web/sites/default/files directory. thus the files sub directory should exist before this action, otherwise the container will fail. You need then to initiate an initContainer who mount the same directory and create the files sub directory in the event this one do not exist. initContainers: - image: uk.icr.io/greenv2-ns/code-php-fpm:latest volumeMounts: - mountPath: /var/www/drupal/web/sites/default name: sites-cos-storage readOnly: false name: create-files command: [ sh , -c , mkdir -p /var/www/drupal/web/sites/default/files ] securityContext: runAsUser: 0 Then any file or diretory created in the /var/www/drupal/web/sites/default sub directory will create an object in the specified IBM COS bucket Here is an example of two PVC created which trigger the create of two buckets: The following example shows how COS is organized via the ibmc-s3fs driver: root@php-fpm-stg-d5bb47bfb-j6hqk:/var/www/drupal/web/sites/default# ls -lR .: total 1 drwxrwxrwx 1 www-data www-data 0 Jul 17 10:19 files ./files: total 1 drwxr-xr-x 1 root root 0 Jul 17 10:20 dir1 drwxr-xr-x 1 root root 0 Jul 17 10:21 dir2 ./files/dir1: total 1 -rw-r--r-- 1 root root 7 Jul 17 10:21 myfile1 ./files/dir2: total 1 -rw-r--r-- 1 root root 7 Jul 17 10:21 myfile2 Each directory (files, dir1, dir2) has an entry in the bucket Each file (myfile1, myfile2) has also an entry in the bucket","title":"Use your Kubernetes PVC in your Kubernetes Drupal pod"},{"location":"FEATURE-LIST/","text":"Feature list It covers these baseline features and scenarios: - [ ] Provides a script scripts/setup-infrastructure.sh that is a placeholder to deploy a Kubernetes cluster and provision the MySQL, Redis, and Memcached services from the IBM Cloud. As an alternative, see the configuration page for the UI instructions. - [x] Provides a script scripts/build-containers.sh that starts with a supported base PHP 5.6 image, injects custom code, runs Composer, tags and pushes the image to an IBM Cloud Container Registry. - [x] Provides a script scripts/deploy-containers.sh to deploy a set of 4 containers (1 NGINX container, 2 PHP-FPM containers, 1 PHP-CLI) from those images and mounts a shared volume to the 3 PHP containers. - [x] Connects the 3 PHP containers to a MySQL-as-a-Service on startup. - [x] Connects the 3 PHP containers to a Redis-as-a-Service on startup. - [x] Connects the 3 PHP containers to a Memcached-as-a-Service on startup. - [x] Exposes a load balanced endpoint that takes an HTTP POST request and routes it through NGINX to the PHP containers, which saves data in the MySQL and Redis databases, stores it in Memcached, and writes a file to the shared file system. - [x] Exposes a load balanced endpoint app/read.php that takes an HTTP GET request and routes it through NGINX to the PHP containers, which retrieves data in the MySQL and Redis databases, retrieves data from Memcached, and reads a file from the shared file system. - [x] Exposes a load balanced endpoint app/create.php that takes an HTTP POST request and routes it through NGINX to the PHP containers, which creates data in the MySQL and Redis databases, caches data from Memcached, and creates a file on the shared file system. - [x] Exposes a load balanced endpoint app/delete.php that takes an HTTP DELETE request and routes it through NGINX to the PHP containers, which deletes data in the MySQL and Redis databases, clears data from Memcached, and deletes a file from the shared file system. - [ ] Builds and redeploys new containers with zero downtime on GitHub push. - [x] Provides a script scripts/destroy-containers.sh to stop and remove the containers (but not the storage volume). - [ ] Provides a script scripts/destroy-infrastructure.sh that is a placeholder to destroy a Kubernetes cluster and deprovision the MySQL, Redis, and Memcached services from the IBM Cloud.","title":"FEATURE LIST"},{"location":"FEATURE-LIST/#feature-list","text":"It covers these baseline features and scenarios: - [ ] Provides a script scripts/setup-infrastructure.sh that is a placeholder to deploy a Kubernetes cluster and provision the MySQL, Redis, and Memcached services from the IBM Cloud. As an alternative, see the configuration page for the UI instructions. - [x] Provides a script scripts/build-containers.sh that starts with a supported base PHP 5.6 image, injects custom code, runs Composer, tags and pushes the image to an IBM Cloud Container Registry. - [x] Provides a script scripts/deploy-containers.sh to deploy a set of 4 containers (1 NGINX container, 2 PHP-FPM containers, 1 PHP-CLI) from those images and mounts a shared volume to the 3 PHP containers. - [x] Connects the 3 PHP containers to a MySQL-as-a-Service on startup. - [x] Connects the 3 PHP containers to a Redis-as-a-Service on startup. - [x] Connects the 3 PHP containers to a Memcached-as-a-Service on startup. - [x] Exposes a load balanced endpoint that takes an HTTP POST request and routes it through NGINX to the PHP containers, which saves data in the MySQL and Redis databases, stores it in Memcached, and writes a file to the shared file system. - [x] Exposes a load balanced endpoint app/read.php that takes an HTTP GET request and routes it through NGINX to the PHP containers, which retrieves data in the MySQL and Redis databases, retrieves data from Memcached, and reads a file from the shared file system. - [x] Exposes a load balanced endpoint app/create.php that takes an HTTP POST request and routes it through NGINX to the PHP containers, which creates data in the MySQL and Redis databases, caches data from Memcached, and creates a file on the shared file system. - [x] Exposes a load balanced endpoint app/delete.php that takes an HTTP DELETE request and routes it through NGINX to the PHP containers, which deletes data in the MySQL and Redis databases, clears data from Memcached, and deletes a file from the shared file system. - [ ] Builds and redeploys new containers with zero downtime on GitHub push. - [x] Provides a script scripts/destroy-containers.sh to stop and remove the containers (but not the storage volume). - [ ] Provides a script scripts/destroy-infrastructure.sh that is a placeholder to destroy a Kubernetes cluster and deprovision the MySQL, Redis, and Memcached services from the IBM Cloud.","title":"Feature list"},{"location":"INITIAL-SETUP/","text":"Initial Setup Guide to all available configuration settings. Provision a Kubernetes cluster on the IBM Cloud Container Service Create a paid IBM Cloud account, and log into the dashboard. Choose Containers from the left hand hamburger navigation. Click the Create cluster button. Select the Standard pay-as-you-go type of cluster (this allows for storage volumes and public floating IPs) and Create. Going back to the Dashboard from the navigation, you'll see your cluster. Click on it to see the cluster Overview. Click on Worker Nodes to get details on your worker nodes. It will take time for the cluster to complete provisioning, so go get some coffee. Connect to your Kubernetes cluster from your workstation Click on the Access link to download and configure the bx and kubectl CLIs. kubectl version =1.7.6 is required. Run the configuration commands, making sure that the $KUBECONFIG variable path is indeed correct (it may not reflect your actual home directory). You can then use kubectl or the kubectl proxy dashboard web UI that starts on localhost to inspect your Kubernetes environment. Provision and bind two MySQL-as-a-Service instances You can do this with the bx command too, but I prefer to work with the dashboard as it's just a one time setup operation with several options to browse through. Go to the hamburger navigation again and choose Data Analytics. Click \"Create\" You have a choice of two MySQL-as-a-Service providers, Compose and ClearDB. ClearDB is quicker to get running with for a PoC. You can use the free plan, but if you need better performance, choose a paid plan. Take note of the credentials, and save them in a scripts/kubernetes/secrets/service-credentials.txt file you copy from scripts/kubernetes/secrets/service-credentials.txt.tpl . There are variables for both a \"Staging\" database instance and a \"Production\" instance. They will be separate databases with separate credentials. For ClearDB, the credentials can be found in the ClearDB Dashboard. Select your database and click the \"System Information\" tab For Compose, the credentials will be shown right before you create the service. The IBM Cloud Container Service offers a way to autobind credentials, but using a secret from this credentials file gives us the option to use services in another organization and space and/or start it up later as its own pod. Repeat these steps to create a second database and make sure you have entries for both in the scripts/kubernetes/secrets/service-credentials.txt file. Provision and bind a Redis-as-a-Service You can do this with the bx command too, but I prefer to work with the dashboard as it's a one time setup operation with several options. Go to the hamburger navigation again and choose Data Analytics. Click \"Create\" You have a choice of two Redis-as-a-Service providers, Compose and Redis Cloud. Redis Cloud has a free tier, so you can just use that. Take note of the credentials, and save them in scripts/kubernetes/secrets/service-credentials.txt . For Compose, the credentials can be found by selecting the service from the dasboard, and clicking \"Service Credentials\" Provision a Memcached instance There is currently no cloud foundry service on IBM Cloud for Memcached. As an alternative we\u2019ll deploy the Memcached helm chart available to deploy on IKS cluster. From the menu on the top left, select Kubernetes - Helm Catalog and filter with ex: memca to see the available charts. ! Select Memcached v2.9.0 In order to install the chart, follow the below instructions helm: cd ~ wget https://kubernetes-helm.storage.googleapis.com/helm-v2.14.0-linux-amd64.tar.gz mkdir helm-v2.14.0 tar zxfv helm-v2.14.0-linux-amd64.tar.gz -C helm-v2.14.0 export PATH=\"$(echo ~)/helm-v2.14.0/linux-amd64:$PATH\" helm init kubectl create serviceaccount --namespace kube-system tiller kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller kubectl patch deploy --namespace kube-system tiller-deploy -p '{\"spec\":{\"template\":{\"spec\":{\"serviceAccount\":\"tiller\"}}}}' helm repo add bitnami https://charts.bitnami.com/bitnami helm install bitnami/memcached -name agd-memcached","title":"Initial Setup"},{"location":"INITIAL-SETUP/#initial-setup","text":"Guide to all available configuration settings.","title":"Initial Setup"},{"location":"INITIAL-SETUP/#provision-a-kubernetes-cluster-on-the-ibm-cloud-container-service","text":"Create a paid IBM Cloud account, and log into the dashboard. Choose Containers from the left hand hamburger navigation. Click the Create cluster button. Select the Standard pay-as-you-go type of cluster (this allows for storage volumes and public floating IPs) and Create. Going back to the Dashboard from the navigation, you'll see your cluster. Click on it to see the cluster Overview. Click on Worker Nodes to get details on your worker nodes. It will take time for the cluster to complete provisioning, so go get some coffee.","title":"Provision a Kubernetes cluster on the IBM Cloud Container Service"},{"location":"INITIAL-SETUP/#connect-to-your-kubernetes-cluster-from-your-workstation","text":"Click on the Access link to download and configure the bx and kubectl CLIs. kubectl version =1.7.6 is required. Run the configuration commands, making sure that the $KUBECONFIG variable path is indeed correct (it may not reflect your actual home directory). You can then use kubectl or the kubectl proxy dashboard web UI that starts on localhost to inspect your Kubernetes environment.","title":"Connect to your Kubernetes cluster from your workstation"},{"location":"INITIAL-SETUP/#provision-and-bind-two-mysql-as-a-service-instances","text":"You can do this with the bx command too, but I prefer to work with the dashboard as it's just a one time setup operation with several options to browse through. Go to the hamburger navigation again and choose Data Analytics. Click \"Create\" You have a choice of two MySQL-as-a-Service providers, Compose and ClearDB. ClearDB is quicker to get running with for a PoC. You can use the free plan, but if you need better performance, choose a paid plan. Take note of the credentials, and save them in a scripts/kubernetes/secrets/service-credentials.txt file you copy from scripts/kubernetes/secrets/service-credentials.txt.tpl . There are variables for both a \"Staging\" database instance and a \"Production\" instance. They will be separate databases with separate credentials. For ClearDB, the credentials can be found in the ClearDB Dashboard. Select your database and click the \"System Information\" tab For Compose, the credentials will be shown right before you create the service. The IBM Cloud Container Service offers a way to autobind credentials, but using a secret from this credentials file gives us the option to use services in another organization and space and/or start it up later as its own pod. Repeat these steps to create a second database and make sure you have entries for both in the scripts/kubernetes/secrets/service-credentials.txt file.","title":"Provision and bind two MySQL-as-a-Service instances"},{"location":"INITIAL-SETUP/#provision-and-bind-a-redis-as-a-service","text":"You can do this with the bx command too, but I prefer to work with the dashboard as it's a one time setup operation with several options. Go to the hamburger navigation again and choose Data Analytics. Click \"Create\" You have a choice of two Redis-as-a-Service providers, Compose and Redis Cloud. Redis Cloud has a free tier, so you can just use that. Take note of the credentials, and save them in scripts/kubernetes/secrets/service-credentials.txt . For Compose, the credentials can be found by selecting the service from the dasboard, and clicking \"Service Credentials\"","title":"Provision and bind a Redis-as-a-Service"},{"location":"INITIAL-SETUP/#provision-a-memcached-instance","text":"There is currently no cloud foundry service on IBM Cloud for Memcached. As an alternative we\u2019ll deploy the Memcached helm chart available to deploy on IKS cluster. From the menu on the top left, select Kubernetes - Helm Catalog and filter with ex: memca to see the available charts. ! Select Memcached v2.9.0 In order to install the chart, follow the below instructions helm: cd ~ wget https://kubernetes-helm.storage.googleapis.com/helm-v2.14.0-linux-amd64.tar.gz mkdir helm-v2.14.0 tar zxfv helm-v2.14.0-linux-amd64.tar.gz -C helm-v2.14.0 export PATH=\"$(echo ~)/helm-v2.14.0/linux-amd64:$PATH\" helm init kubectl create serviceaccount --namespace kube-system tiller kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller kubectl patch deploy --namespace kube-system tiller-deploy -p '{\"spec\":{\"template\":{\"spec\":{\"serviceAccount\":\"tiller\"}}}}' helm repo add bitnami https://charts.bitnami.com/bitnami helm install bitnami/memcached -name agd-memcached","title":"Provision a Memcached instance"},{"location":"LOCAL-KUBERNETES/","text":"Installing MiniKube TODO Using MiniKube Start Minikube minikube start Starting local Kubernetes cluster... Starting VM... Getting VM IP address... Moving files into cluster... Setting up certs... Connecting to cluster... Setting up kubeconfig... Starting cluster components... Kubectl is now configured to use the cluster. Check status kubectl get nodes NAME STATUS ROLES AGE VERSION minikube Ready none 6m v1.7.5 If opening another terminal windows, point Docker and Kubectl to Minikube eval $(minikube docker-env) Accessing services in Minikube Switching the nginx service from LoadBalancer to NodePort : \u2514\u2500[$] kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.0.0.1 none 443/TCP 1d nginx LoadBalancer 10.0.0.34 pending 80:32352/TCP 1d php-fpm ClusterIP 10.0.0.93 none 9000/TCP 1d # Change spec.type to NodePort \u2514\u2500[$] kubectl edit service nginx service \"nginx\" edited \u2514\u2500[$] kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.0.0.1 none 443/TCP 1d nginx NodePort 10.0.0.34 none 80:32352/TCP 1d php-fpm ClusterIP 10.0.0.93 none 9000/TCP 1d \u2514\u2500[$] minikube service nginx Opening kubernetes service default/nginx in default browser... \u2514\u2500[$] minikube service nginx --url http://192.168.99.100:32352 MiniKube load balancer and nodeports https://github.com/kubernetes/minikube/issues/950 Currently minikube doesn't support LoadBalancer, it doesn't assign to it external IP. And services are supposed to access using minikube service service-name... is uses port mapping and it is quite cumbersome (esp if service exposes more then one port) https://github.com/kubernetes/minikube/issues/38 Referenced by #950, #950 marked as a dupe of #38. https://medium.com/@claudiopro/getting-started-with-kubernetes-via-minikube-ada8c7a29620 Note we must use the type=NodePort because minikube doesn\u2019t support the LoadBalancer service. $ kubectl expose deployment hello-node --type=NodePort $ kubectl get services $ curl $(minikube service hello-node --url) https://github.com/kubernetes/minikube/issues/384 LoadBalancer services run fine on minikube, just with no real external load balancer created. LoadBalancer services get a node port assigned too so you can access services via minikube service name to open browser or add --url flag to output service URL to terminal. Would that cover what you need or is there something more that you'd like to see?","title":"LOCAL KUBERNETES"},{"location":"LOCAL-KUBERNETES/#installing-minikube","text":"TODO","title":"Installing MiniKube"},{"location":"LOCAL-KUBERNETES/#using-minikube","text":"Start Minikube minikube start Starting local Kubernetes cluster... Starting VM... Getting VM IP address... Moving files into cluster... Setting up certs... Connecting to cluster... Setting up kubeconfig... Starting cluster components... Kubectl is now configured to use the cluster. Check status kubectl get nodes NAME STATUS ROLES AGE VERSION minikube Ready none 6m v1.7.5 If opening another terminal windows, point Docker and Kubectl to Minikube eval $(minikube docker-env)","title":"Using MiniKube"},{"location":"LOCAL-KUBERNETES/#accessing-services-in-minikube","text":"Switching the nginx service from LoadBalancer to NodePort : \u2514\u2500[$] kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.0.0.1 none 443/TCP 1d nginx LoadBalancer 10.0.0.34 pending 80:32352/TCP 1d php-fpm ClusterIP 10.0.0.93 none 9000/TCP 1d # Change spec.type to NodePort \u2514\u2500[$] kubectl edit service nginx service \"nginx\" edited \u2514\u2500[$] kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.0.0.1 none 443/TCP 1d nginx NodePort 10.0.0.34 none 80:32352/TCP 1d php-fpm ClusterIP 10.0.0.93 none 9000/TCP 1d \u2514\u2500[$] minikube service nginx Opening kubernetes service default/nginx in default browser... \u2514\u2500[$] minikube service nginx --url http://192.168.99.100:32352","title":"Accessing services in Minikube"},{"location":"LOCAL-KUBERNETES/#minikube-load-balancer-and-nodeports","text":"https://github.com/kubernetes/minikube/issues/950 Currently minikube doesn't support LoadBalancer, it doesn't assign to it external IP. And services are supposed to access using minikube service service-name... is uses port mapping and it is quite cumbersome (esp if service exposes more then one port) https://github.com/kubernetes/minikube/issues/38 Referenced by #950, #950 marked as a dupe of #38. https://medium.com/@claudiopro/getting-started-with-kubernetes-via-minikube-ada8c7a29620 Note we must use the type=NodePort because minikube doesn\u2019t support the LoadBalancer service. $ kubectl expose deployment hello-node --type=NodePort $ kubectl get services $ curl $(minikube service hello-node --url) https://github.com/kubernetes/minikube/issues/384 LoadBalancer services run fine on minikube, just with no real external load balancer created. LoadBalancer services get a node port assigned too so you can access services via minikube service name to open browser or add --url flag to output service URL to terminal. Would that cover what you need or is there something more that you'd like to see?","title":"MiniKube load balancer and nodeports"},{"location":"ONGOING-DEVELOPMENT/","text":"Ongoing development Now that the Kubernetes cluster is provisioned and you have a set of containers running, the ongoing DevOps workflow will be to write code locally, push that to GitHub into the config or code directories, and that in turn will start a job to rebuild the container images with the versioned code. These images are in turn pushed to the private Docker registry, and pulled to run on the pods. Updating the base image configuration Push updates to the config directory. The pipeline will detect changes and initiate a base image rebuild, and then another build on top for the code files. Updating the Drupal and code version Push updates to the code directory. The pipeline will detect changes and initiate a custom image rebuild. Addressing security issues with Vulnerability Advisor As container images are built and pushed to the IBM Cloud Container Registry, they are automatically scanned by the Vulnerability Advisor. You can see whether there are any vulnerabilities in your images by listing the images: ibmcloud cr images If any of them are listed as Vulnerable you can then see the specific issues with: ibmcloud cr va $IMAGE_NAME","title":"ONGOING DEVELOPMENT"},{"location":"ONGOING-DEVELOPMENT/#ongoing-development","text":"Now that the Kubernetes cluster is provisioned and you have a set of containers running, the ongoing DevOps workflow will be to write code locally, push that to GitHub into the config or code directories, and that in turn will start a job to rebuild the container images with the versioned code. These images are in turn pushed to the private Docker registry, and pulled to run on the pods.","title":"Ongoing development"},{"location":"ONGOING-DEVELOPMENT/#updating-the-base-image-configuration","text":"Push updates to the config directory. The pipeline will detect changes and initiate a base image rebuild, and then another build on top for the code files.","title":"Updating the base image configuration"},{"location":"ONGOING-DEVELOPMENT/#updating-the-drupal-and-code-version","text":"Push updates to the code directory. The pipeline will detect changes and initiate a custom image rebuild.","title":"Updating the Drupal and code version"},{"location":"ONGOING-DEVELOPMENT/#addressing-security-issues-with-vulnerability-advisor","text":"As container images are built and pushed to the IBM Cloud Container Registry, they are automatically scanned by the Vulnerability Advisor. You can see whether there are any vulnerabilities in your images by listing the images: ibmcloud cr images If any of them are listed as Vulnerable you can then see the specific issues with: ibmcloud cr va $IMAGE_NAME","title":"Addressing security issues with Vulnerability Advisor"},{"location":"PHP-CLI-DRUSH/","text":"Managing Drupal clusters You can use the PHP-CLI container to execute regular bash commands or drush commands against the deployed staging and production systems. Execute arbitrary commands Use kubectl get pods to find the name of the PHP-CLI container Use scripts/pipeline/kube-exec.sh and pass the name of the container instance You will be in the /root/drush/ folder where you can run ad hoc commands or scripts added to the image from the code/drush directory. For example ./transfer-data.sh or ./transfer-files.sh You can also invoke those as a one liner with kubectl exec $PHP_CLI_CONTAINER_NAME /root/drush/transfer-data.sh kubectl exec $PHP_CLI_CONTAINER_NAME /root/drush/transfer-files.sh Execute Drush commands As above, you can exec into the PHP-CLI container and run drush commands as needed. For example drush sql-cli --db-url=\"mysql://${MYSQL_USER_STG}:${MYSQL_PASS_STG}@${MYSQL_HOST_STG}:${MYSQL_PORT_STG}/${MYSQL_NAME_STG}\" drush sql-cli --db-url=\"mysql://${MYSQL_USER_PRD}:${MYSQL_PASS_PRD}@${MYSQL_HOST_PRD}:${MYSQL_PORT_PRD}/${MYSQL_NAME_PRD}\"","title":"PHP CLI DRUSH"},{"location":"PHP-CLI-DRUSH/#managing-drupal-clusters","text":"You can use the PHP-CLI container to execute regular bash commands or drush commands against the deployed staging and production systems.","title":"Managing Drupal clusters"},{"location":"PHP-CLI-DRUSH/#execute-arbitrary-commands","text":"Use kubectl get pods to find the name of the PHP-CLI container Use scripts/pipeline/kube-exec.sh and pass the name of the container instance You will be in the /root/drush/ folder where you can run ad hoc commands or scripts added to the image from the code/drush directory. For example ./transfer-data.sh or ./transfer-files.sh You can also invoke those as a one liner with kubectl exec $PHP_CLI_CONTAINER_NAME /root/drush/transfer-data.sh kubectl exec $PHP_CLI_CONTAINER_NAME /root/drush/transfer-files.sh","title":"Execute arbitrary commands"},{"location":"PHP-CLI-DRUSH/#execute-drush-commands","text":"As above, you can exec into the PHP-CLI container and run drush commands as needed. For example drush sql-cli --db-url=\"mysql://${MYSQL_USER_STG}:${MYSQL_PASS_STG}@${MYSQL_HOST_STG}:${MYSQL_PORT_STG}/${MYSQL_NAME_STG}\" drush sql-cli --db-url=\"mysql://${MYSQL_USER_PRD}:${MYSQL_PASS_PRD}@${MYSQL_HOST_PRD}:${MYSQL_PORT_PRD}/${MYSQL_NAME_PRD}\"","title":"Execute Drush commands"},{"location":"PIPELINE-SETUP/","text":"Toolchain Introduction Guide to all available configuration settings. This toolchain will enable your containers to automatically build and push to a registry as well as deploy to a Kubernetes cluster hosted on the IBM Cloud. This toolchain will be comprised of multiple pipelines, one for each major component of the cluster. Ideally there would be four different layers in build/deploy process: Push code to repository Check to see what directories have been changed If config directory has been changed, rebuild base images and code layer If code directory has been changed, only build the code layer Build images Test images with Vulnerability Advisor. Deploy to staging environment Deploy to production environment Each of these layers could come from a different repository and could be built and deployed when code is pushed. For the purpose of this POC, we have one repo that contains all of our images and custom code. Our finished toolchain will appear as follows: Building the Toolchain To get started, click on the \"hamburger\" menu at the top left of Bluemix and select Dev Ops . Click on Toolchains on the left pane Click Create Toolchain Scroll down to Other Templates and select Build Your Own Toolchain Name toolchain and click Create Click on Add a Tool Click on Git Repos and Issue Tracking Fill in details Select Clone Enter the URL to Dan's repo Enter a Repository name (or not) Make sure the Track deployment of code changes checkbox is checked. This will allow the pipeline to trigger automatically with code changes. Click Create Integration Add another tool Select Delivery Pipeline Name the pipeline nginx Click Create Integration Before moving on, we need to get an IBM Cloud API key. Click on Manage at the top right, hover over Security and select IBM Cloud API keys . Click on Create , give your key a name and description, click Create. Click Show and copy your API key. Make absolutely sure that you copied the key correctly because after you leave this page, you will not be able to see the key again. Go back to your toolchain. You can get there by clicking on the menu at the top left, selecting DevOps , then selecting your toolchain from the list. On the toolchain page, click on the Delivery Pipeline. Click Add Stage Make changes to Input tab. Give stage a name Ensure git URL and branch are correct Ensure that Run jobs whenever a change is pushed to Git is selected. This will allow for the container images to build automatically. Click on the Jobs tab. Click on Add Job and select Build . Under Builder Type select Container Registry . Under API Key see if your IBM Cloud API Key appears. If not, click on Add an existing API Key and enter the API key that you copied earlier. For IBM Cloud Container Registry namespace enter jjdojo In Docker image name enter nginx In the Build Script section enter the following: bash echo \"Calling the build script\" cd scripts/pipeline . ./buildImage.sh Leave the rest as it is and click on Save at the bottom of the stage. Next, create another stage and name it Test . In this stage you can run any custom test scripts or use the built-in Vulnerability Advisor. Click on the jobs tab, add a new job, and select Test . Under Tester Type , select Vulnerability Advisor Under API Key slect the key for your org or enter a new one Under Bluemix Container Registry Namespace enter your Namespace Select the Docker Image Name and Docker Image Tag that you want to test. Add any additional testing scripts in the Test Script area. When done, click Save Once you are back on the pipeline page, click Add Stage again. Now we need to add our stage for deploying to the staging environemnt. Name the stage Staging and make sure the input is coming from the previous build stage as seen below. Next, click on the Jobs tab and click Add job and select Deploy . For Deployer Type select kubernetes Enter your API Key under API Key Select the cluster that you would like to deploy to. In the Deploy Script section, enter the following: ```bash #!/bin/bash . scripts/pipeline/pipelineDeployScripts/nginx-deploy.sh ``` Next we need to add an environment variable to tell the script which environment we are deploying to. Click on the Environment Properties tab. Click Add Property , select Text Property , and under name enter ENVIRONMENT and under Value enter stg . When done, click on Save Next, we need to create another deployment stage but this time we will deploy to the production environment. Repeat steps 22 - 24 but this time, name the stage Production , and for the environment property, enter prd . The deploy script for both environments will be the same. We should now have four stages in our nginx pipeline. This pipeline will handle the building, testing, and deploying of the nginx container in two different environments. We now need to add pipelines for our other containers. Click on the toolchain name at the top left of the page to take you back to the toolchain page. Follow steps 14 - 25 to create pipelines for the other images while making sure to change the image names for the respective pipeline as well as making sure that the registry namespace and targeted cluster remains the same. Be sure to change the deploy script for each pipeline as follows: Note that php-cli does not need to be deployed into both environments For php-cli: ```bash #!/bin/bash . scripts/pipeline/pipelineDeployScripts/php-cli-deploy.sh ``` For php-fpm: ```bash #!/bin/bash . scripts/pipeline/pipelineDeployScripts/php-fpm-deploy.sh ``` Next, we need to add the step to build the persistent volumes. Create one more pipeline and name it Persistent Volumes Click on it to configure the pipeline and add a new stage. Add a new Deploy job, for Deployer Type select Kubernetes , enter your API Key, and select your target cluster. For the in the Deploy Script section, enter the following: bash #!/bin/bash kubectl apply -f scripts/kubernetes/persistent-volumes.yaml When done, click Save . Now we just need to add one last pipeline that will allow us to manually run scripts to transfer files and data between environments. Click on the toolchain name at the top left to go back to the toolchain page. Click Add a Tool Select Delivery Pipeline Name the pipeline Data Sync Once the pipeline has been created, click on it to configure the stages. Click Add Stage and name the stage Transfer Files On the Input tab, change the Stage Trigger to Run jobs only when this stage is run manually Click on the Jobs tab Click Add Job and select Deploy Name the job Transfer Files Set the Deployer Type to Kubernetes Verify the API Key , Target , and Kubernetes Cluster For the Deploy Script enter the following: ```bash #!/bin/bash echo $(kubectl get pod -l \"app=php-cli\" -o jsonpath='{.items[0].metadata.name}') kubectl exec $(kubectl get pod -l \"app=php-cli\" -o jsonpath='{.items[0].metadata.name}') /root/drush/transfer-files.sh ``` - Click Save 34. Add another stage - Name the stage Transfer Data - Click on the Input tab and set the Stage Trigger to Run jobs only when this stage is run manually Click on the Jobs tab Click Add Job and select Deploy Name the job Transfer Data Set the Deployer Type to Kubernetes Verify the API Key , Target , and Kubernetes Cluster For the Deploy Script enter the following: ```bash #!/bin/bash echo $(kubectl get pod -l \"app=php-cli\" -o jsonpath='{.items[0].metadata.name}') kubectl exec $(kubectl get pod -l \"app=php-cli\" -o jsonpath='{.items[0].metadata.name}') /root/drush/transfer-data.sh ``` - Click Save Our toolchain is now configured and should look similar to the image below: All that we have to do now is push a change to our repo to automatically kick off the pipeline.","title":"Toolchain Introduction"},{"location":"PIPELINE-SETUP/#toolchain-introduction","text":"Guide to all available configuration settings. This toolchain will enable your containers to automatically build and push to a registry as well as deploy to a Kubernetes cluster hosted on the IBM Cloud. This toolchain will be comprised of multiple pipelines, one for each major component of the cluster. Ideally there would be four different layers in build/deploy process: Push code to repository Check to see what directories have been changed If config directory has been changed, rebuild base images and code layer If code directory has been changed, only build the code layer Build images Test images with Vulnerability Advisor. Deploy to staging environment Deploy to production environment Each of these layers could come from a different repository and could be built and deployed when code is pushed. For the purpose of this POC, we have one repo that contains all of our images and custom code. Our finished toolchain will appear as follows:","title":"Toolchain Introduction"},{"location":"PIPELINE-SETUP/#building-the-toolchain","text":"To get started, click on the \"hamburger\" menu at the top left of Bluemix and select Dev Ops . Click on Toolchains on the left pane Click Create Toolchain Scroll down to Other Templates and select Build Your Own Toolchain Name toolchain and click Create Click on Add a Tool Click on Git Repos and Issue Tracking Fill in details Select Clone Enter the URL to Dan's repo Enter a Repository name (or not) Make sure the Track deployment of code changes checkbox is checked. This will allow the pipeline to trigger automatically with code changes. Click Create Integration Add another tool Select Delivery Pipeline Name the pipeline nginx Click Create Integration Before moving on, we need to get an IBM Cloud API key. Click on Manage at the top right, hover over Security and select IBM Cloud API keys . Click on Create , give your key a name and description, click Create. Click Show and copy your API key. Make absolutely sure that you copied the key correctly because after you leave this page, you will not be able to see the key again. Go back to your toolchain. You can get there by clicking on the menu at the top left, selecting DevOps , then selecting your toolchain from the list. On the toolchain page, click on the Delivery Pipeline. Click Add Stage Make changes to Input tab. Give stage a name Ensure git URL and branch are correct Ensure that Run jobs whenever a change is pushed to Git is selected. This will allow for the container images to build automatically. Click on the Jobs tab. Click on Add Job and select Build . Under Builder Type select Container Registry . Under API Key see if your IBM Cloud API Key appears. If not, click on Add an existing API Key and enter the API key that you copied earlier. For IBM Cloud Container Registry namespace enter jjdojo In Docker image name enter nginx In the Build Script section enter the following: bash echo \"Calling the build script\" cd scripts/pipeline . ./buildImage.sh Leave the rest as it is and click on Save at the bottom of the stage. Next, create another stage and name it Test . In this stage you can run any custom test scripts or use the built-in Vulnerability Advisor. Click on the jobs tab, add a new job, and select Test . Under Tester Type , select Vulnerability Advisor Under API Key slect the key for your org or enter a new one Under Bluemix Container Registry Namespace enter your Namespace Select the Docker Image Name and Docker Image Tag that you want to test. Add any additional testing scripts in the Test Script area. When done, click Save Once you are back on the pipeline page, click Add Stage again. Now we need to add our stage for deploying to the staging environemnt. Name the stage Staging and make sure the input is coming from the previous build stage as seen below. Next, click on the Jobs tab and click Add job and select Deploy . For Deployer Type select kubernetes Enter your API Key under API Key Select the cluster that you would like to deploy to. In the Deploy Script section, enter the following: ```bash #!/bin/bash . scripts/pipeline/pipelineDeployScripts/nginx-deploy.sh ``` Next we need to add an environment variable to tell the script which environment we are deploying to. Click on the Environment Properties tab. Click Add Property , select Text Property , and under name enter ENVIRONMENT and under Value enter stg . When done, click on Save Next, we need to create another deployment stage but this time we will deploy to the production environment. Repeat steps 22 - 24 but this time, name the stage Production , and for the environment property, enter prd . The deploy script for both environments will be the same. We should now have four stages in our nginx pipeline. This pipeline will handle the building, testing, and deploying of the nginx container in two different environments. We now need to add pipelines for our other containers. Click on the toolchain name at the top left of the page to take you back to the toolchain page. Follow steps 14 - 25 to create pipelines for the other images while making sure to change the image names for the respective pipeline as well as making sure that the registry namespace and targeted cluster remains the same. Be sure to change the deploy script for each pipeline as follows: Note that php-cli does not need to be deployed into both environments For php-cli: ```bash #!/bin/bash . scripts/pipeline/pipelineDeployScripts/php-cli-deploy.sh ``` For php-fpm: ```bash #!/bin/bash . scripts/pipeline/pipelineDeployScripts/php-fpm-deploy.sh ``` Next, we need to add the step to build the persistent volumes. Create one more pipeline and name it Persistent Volumes Click on it to configure the pipeline and add a new stage. Add a new Deploy job, for Deployer Type select Kubernetes , enter your API Key, and select your target cluster. For the in the Deploy Script section, enter the following: bash #!/bin/bash kubectl apply -f scripts/kubernetes/persistent-volumes.yaml When done, click Save . Now we just need to add one last pipeline that will allow us to manually run scripts to transfer files and data between environments. Click on the toolchain name at the top left to go back to the toolchain page. Click Add a Tool Select Delivery Pipeline Name the pipeline Data Sync Once the pipeline has been created, click on it to configure the stages. Click Add Stage and name the stage Transfer Files On the Input tab, change the Stage Trigger to Run jobs only when this stage is run manually Click on the Jobs tab Click Add Job and select Deploy Name the job Transfer Files Set the Deployer Type to Kubernetes Verify the API Key , Target , and Kubernetes Cluster For the Deploy Script enter the following: ```bash #!/bin/bash echo $(kubectl get pod -l \"app=php-cli\" -o jsonpath='{.items[0].metadata.name}') kubectl exec $(kubectl get pod -l \"app=php-cli\" -o jsonpath='{.items[0].metadata.name}') /root/drush/transfer-files.sh ``` - Click Save 34. Add another stage - Name the stage Transfer Data - Click on the Input tab and set the Stage Trigger to Run jobs only when this stage is run manually Click on the Jobs tab Click Add Job and select Deploy Name the job Transfer Data Set the Deployer Type to Kubernetes Verify the API Key , Target , and Kubernetes Cluster For the Deploy Script enter the following: ```bash #!/bin/bash echo $(kubectl get pod -l \"app=php-cli\" -o jsonpath='{.items[0].metadata.name}') kubectl exec $(kubectl get pod -l \"app=php-cli\" -o jsonpath='{.items[0].metadata.name}') /root/drush/transfer-data.sh ``` - Click Save Our toolchain is now configured and should look similar to the image below: All that we have to do now is push a change to our repo to automatically kick off the pipeline.","title":"Building the Toolchain"},{"location":"SYNCHRONIZING-DATA/","text":"Synchronizing data and drush scripts From time to time you may want to bring production data and files into the staging environment so that you have comparable environments. Synchronizing files Execute the transfer-files.sh script. This can be done by connecting to the PHP-CLI container. kubectl exec $CONTAINER_NAME /root/drush/transfer-files.sh Synchronizing data Execute the transfer-data.sh script. kubectl exec $CONTAINER_NAME /root/drush/transfer-data.sh Executing drush scripts Execute the drush-status.sh script. kubectl exec $CONTAINER_NAME /var/www/drupal/drush/drush-status.sh Running arbitrary commands You can enter a running container and execute commands by passing the container name to the kube-exec.sh script.","title":"SYNCHRONIZING DATA"},{"location":"SYNCHRONIZING-DATA/#synchronizing-data-and-drush-scripts","text":"From time to time you may want to bring production data and files into the staging environment so that you have comparable environments.","title":"Synchronizing data and drush scripts"},{"location":"SYNCHRONIZING-DATA/#synchronizing-files","text":"Execute the transfer-files.sh script. This can be done by connecting to the PHP-CLI container. kubectl exec $CONTAINER_NAME /root/drush/transfer-files.sh","title":"Synchronizing files"},{"location":"SYNCHRONIZING-DATA/#synchronizing-data","text":"Execute the transfer-data.sh script. kubectl exec $CONTAINER_NAME /root/drush/transfer-data.sh","title":"Synchronizing data"},{"location":"SYNCHRONIZING-DATA/#executing-drush-scripts","text":"Execute the drush-status.sh script. kubectl exec $CONTAINER_NAME /var/www/drupal/drush/drush-status.sh","title":"Executing drush scripts"},{"location":"SYNCHRONIZING-DATA/#running-arbitrary-commands","text":"You can enter a running container and execute commands by passing the container name to the kube-exec.sh script.","title":"Running arbitrary commands"},{"location":"about/","text":"Team members Fr\u00e9d\u00e9ric Dutheil - frederic_dutheil@fr.ibm.com Abdoul Gadiri Diallo - abdoul.gadiri.diallo@be.ibm.com Vann Lam - vann.lam@fr.ibm.com Useful links Kanban Project overview with Bluesight GitHub repository App Modernization Map Part Technology used Architecture Microservices Delivery DevOps Toolchain Infrastructure Kubernetes Cluster (IKS) Multi-cloud Single Cloud Vendor (IBM Cloud) Open Flexible Architecture with Open Components (Drupal, MySQL, Redis ...) Security Protected with Certs (IBM Cloud Sercurity offering) Networking Customized Networking (Feature: using netwok policy) Lessons Learned IBM Kubernetes Service (IKS) Very simply to create your first kubernetes cluster Understand how to use persistent storage on IKS with different offering. How to use Cloud Object Storage (COS) as persistent volume and integration with IKS Security Capability to create and manage certificates with IBM Cloud offering : IBM Certificat Manager, IBM Cloud Internet Service, IBM Cloud Domain Name Service Vulnarability in the docker images. IBM Cloud platform provide the capability to check the vulnerability of an image. Each vulnarability is notified in the image registry dashboard Drupal Need to understand how Drupal ecosystem works: requirement, customisation and tools to manage it (drush) Using compose to create the docker image. Continious delivery Toolchain Using toolchain to create a delivery pipeline to create and deploy image Add Github update event to start the delivery pipeline Use Slack to be notified for delivery pipeline exection and status.","title":"About"},{"location":"about/#team-members","text":"Fr\u00e9d\u00e9ric Dutheil - frederic_dutheil@fr.ibm.com Abdoul Gadiri Diallo - abdoul.gadiri.diallo@be.ibm.com Vann Lam - vann.lam@fr.ibm.com","title":"Team members"},{"location":"about/#useful-links","text":"Kanban Project overview with Bluesight GitHub repository","title":"Useful links"},{"location":"about/#app-modernization-map","text":"Part Technology used Architecture Microservices Delivery DevOps Toolchain Infrastructure Kubernetes Cluster (IKS) Multi-cloud Single Cloud Vendor (IBM Cloud) Open Flexible Architecture with Open Components (Drupal, MySQL, Redis ...) Security Protected with Certs (IBM Cloud Sercurity offering) Networking Customized Networking (Feature: using netwok policy)","title":"App Modernization Map"},{"location":"about/#lessons-learned","text":"","title":"Lessons Learned"},{"location":"about/#ibm-kubernetes-service-iks","text":"Very simply to create your first kubernetes cluster Understand how to use persistent storage on IKS with different offering. How to use Cloud Object Storage (COS) as persistent volume and integration with IKS","title":"IBM Kubernetes Service (IKS)"},{"location":"about/#security","text":"Capability to create and manage certificates with IBM Cloud offering : IBM Certificat Manager, IBM Cloud Internet Service, IBM Cloud Domain Name Service Vulnarability in the docker images. IBM Cloud platform provide the capability to check the vulnerability of an image. Each vulnarability is notified in the image registry dashboard","title":"Security"},{"location":"about/#drupal","text":"Need to understand how Drupal ecosystem works: requirement, customisation and tools to manage it (drush) Using compose to create the docker image.","title":"Drupal"},{"location":"about/#continious-delivery-toolchain","text":"Using toolchain to create a delivery pipeline to create and deploy image Add Github update event to start the delivery pipeline Use Slack to be notified for delivery pipeline exection and status.","title":"Continious delivery Toolchain"},{"location":"appmodernizationmap/","text":"App Modernization Map Part Technology used Architecture Microservices Delivery DevOps Toolchain Infrastructure Kubernetes Cluster (IKS) Multi-cloud Single Cloud Vendor (IBM Cloud) Open Flexible Architecture with Open Components (Drupal, MySQL, Redis ...) Security Protected with Certs (IBM Cloud Sercurity offering) Networking Customized Networking (Feature: using netwok policy)","title":"App Modernization Map"},{"location":"appmodernizationmap/#app-modernization-map","text":"Part Technology used Architecture Microservices Delivery DevOps Toolchain Infrastructure Kubernetes Cluster (IKS) Multi-cloud Single Cloud Vendor (IBM Cloud) Open Flexible Architecture with Open Components (Drupal, MySQL, Redis ...) Security Protected with Certs (IBM Cloud Sercurity offering) Networking Customized Networking (Feature: using netwok policy)","title":"App Modernization Map"},{"location":"lessons/","text":"Lessons Learned IBM Kubernetes Service (IKS) Very simply to create your first kubernetes cluster Understand how to use persistent storage on IKS with different offering. How to use Cloud Object Storage (COS) as persistent volume and integration with IKS Security Capability to create and manage certificates with IBM Cloud offering : IBM Certificat Manager, IBM Cloud Internet Service, IBM Cloud Domain Name Service Vulnarability in the docker images. IBM Cloud platform provide the capability to check the vulnerability of an image. Each vulnarability is notified in the image registry dashboard Drupal Need to understand how Drupal ecosystem works: requirement, customisation and tools to manage it (drush) Using compose to create the docker image. Continious delivery Toolchain Using toolchain to create a delivery pipeline to create and deploy image Add Github update event to start the delivery pipeline Use Slack to be notified for delivery pipeline exection and status.","title":"Lessons Learned"},{"location":"lessons/#lessons-learned","text":"","title":"Lessons Learned"},{"location":"lessons/#ibm-kubernetes-service-iks","text":"Very simply to create your first kubernetes cluster Understand how to use persistent storage on IKS with different offering. How to use Cloud Object Storage (COS) as persistent volume and integration with IKS","title":"IBM Kubernetes Service (IKS)"},{"location":"lessons/#security","text":"Capability to create and manage certificates with IBM Cloud offering : IBM Certificat Manager, IBM Cloud Internet Service, IBM Cloud Domain Name Service Vulnarability in the docker images. IBM Cloud platform provide the capability to check the vulnerability of an image. Each vulnarability is notified in the image registry dashboard","title":"Security"},{"location":"lessons/#drupal","text":"Need to understand how Drupal ecosystem works: requirement, customisation and tools to manage it (drush) Using compose to create the docker image.","title":"Drupal"},{"location":"lessons/#continious-delivery-toolchain","text":"Using toolchain to create a delivery pipeline to create and deploy image Add Github update event to start the delivery pipeline Use Slack to be notified for delivery pipeline exection and status.","title":"Continious delivery Toolchain"}]}